{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8948890,"sourceType":"datasetVersion","datasetId":5385235},{"sourceId":8993126,"sourceType":"datasetVersion","datasetId":5416828},{"sourceId":8993346,"sourceType":"datasetVersion","datasetId":5416980},{"sourceId":9086944,"sourceType":"datasetVersion","datasetId":5482927},{"sourceId":9088327,"sourceType":"datasetVersion","datasetId":5483938},{"sourceId":9089052,"sourceType":"datasetVersion","datasetId":5484469},{"sourceId":9089444,"sourceType":"datasetVersion","datasetId":5484754},{"sourceId":9121936,"sourceType":"datasetVersion","datasetId":5506630}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:09.461019Z","iopub.execute_input":"2025-11-05T14:33:09.461914Z","iopub.status.idle":"2025-11-05T14:33:09.520290Z","shell.execute_reply.started":"2025-11-05T14:33:09.461879Z","shell.execute_reply":"2025-11-05T14:33:09.518941Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/area3-14features-010-jak/area3_features_010_jakteristics_14.csv\n/kaggle/input/area3-14features-025-jak/area3_features_025_jakteristics_14.csv\n/kaggle/input/14features-015-jak/features_015_jakteristics_14.csv\n/kaggle/input/14features-025-jak/features_025_jakteristics_14.csv\n/kaggle/input/area3-14features-020-jak/area3_features_020_jakteristics_14.csv\n/kaggle/input/14features-020-jak/features_020_jakteristics_14.csv\n/kaggle/input/area3-14features-015-jak/area3_features_015_jakteristics_14.csv\n/kaggle/input/14features-010-jak/features_010_jakteristics_14.csv\n","output_type":"stream"}],"execution_count":387},{"cell_type":"code","source":"np.random.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:09.522842Z","iopub.execute_input":"2025-11-05T14:33:09.523865Z","iopub.status.idle":"2025-11-05T14:33:09.528760Z","shell.execute_reply.started":"2025-11-05T14:33:09.523810Z","shell.execute_reply":"2025-11-05T14:33:09.527532Z"}},"outputs":[],"execution_count":388},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/14features-025-jak/features_025_jakteristics_14.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:09.530384Z","iopub.execute_input":"2025-11-05T14:33:09.530718Z","iopub.status.idle":"2025-11-05T14:33:10.336765Z","shell.execute_reply.started":"2025-11-05T14:33:09.530689Z","shell.execute_reply":"2025-11-05T14:33:10.335661Z"}},"outputs":[],"execution_count":389},{"cell_type":"code","source":"data = data.drop(['Unnamed: 0'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.338407Z","iopub.execute_input":"2025-11-05T14:33:10.338771Z","iopub.status.idle":"2025-11-05T14:33:10.352910Z","shell.execute_reply.started":"2025-11-05T14:33:10.338740Z","shell.execute_reply":"2025-11-05T14:33:10.351687Z"}},"outputs":[],"execution_count":390},{"cell_type":"code","source":"data = data.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.357175Z","iopub.execute_input":"2025-11-05T14:33:10.357628Z","iopub.status.idle":"2025-11-05T14:33:10.392245Z","shell.execute_reply.started":"2025-11-05T14:33:10.357595Z","shell.execute_reply":"2025-11-05T14:33:10.390697Z"}},"outputs":[],"execution_count":391},{"cell_type":"code","source":"data = data.reset_index()\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.393420Z","iopub.execute_input":"2025-11-05T14:33:10.393750Z","iopub.status.idle":"2025-11-05T14:33:10.431458Z","shell.execute_reply.started":"2025-11-05T14:33:10.393725Z","shell.execute_reply":"2025-11-05T14:33:10.430261Z"}},"outputs":[{"execution_count":392,"output_type":"execute_result","data":{"text/plain":"         index         x        y         z  eigenvalue_sum  omnivariance  \\\n0            0  0.001387  1.10728  0.017115        0.009678      0.001906   \n1            1  0.001387  1.10974  0.017115        0.009722      0.001922   \n2            2  0.001541  1.11221  0.017115        0.009777      0.001942   \n3            3  0.001541  1.11221  0.017115        0.009777      0.001942   \n4            4  0.003545  1.11714  0.017115        0.009984      0.002006   \n...        ...       ...      ...       ...             ...           ...   \n266670  266670  1.066120  1.76079  0.021406        0.012606      0.002211   \n266671  266671  1.066280  1.76079  0.017115        0.012553      0.002200   \n266672  266672  1.066430  1.76326  0.017115        0.012362      0.002183   \n266673  266673  1.066430  1.76572  0.017115        0.012255      0.002170   \n266674  266674  1.069670  1.76326  0.017115        0.012193      0.002159   \n\n        eigenentropy  anisotropy  planarity  linearity      PCA1      PCA2  \\\n0           0.052286    0.941992   0.413554   0.528438  0.653779  0.308297   \n1           0.052496    0.941257   0.414403   0.526854  0.652789  0.308864   \n2           0.052758    0.940384   0.415397   0.524987  0.651624  0.309529   \n3           0.052758    0.940384   0.415397   0.524987  0.651624  0.309529   \n4           0.053715    0.938070   0.417451   0.520619  0.648798  0.311021   \n...              ...         ...        ...        ...       ...       ...   \n266670      0.063959    0.959203   0.335449   0.623754  0.705695  0.265515   \n266671      0.063749    0.959310   0.336689   0.622621  0.705184  0.266122   \n266672      0.063032    0.958494   0.344354   0.614140  0.700591  0.270330   \n266673      0.062621    0.958184   0.348266   0.609918  0.698373  0.272423   \n266674      0.062339    0.958052   0.342147   0.615905  0.701241  0.269343   \n\n        surface_variation  sphericity  verticality        nx        ny  \\\n0                0.037924    0.058008     0.006182  0.025704  0.108003   \n1                0.038347    0.058743     0.006097  0.027464  0.106778   \n2                0.038847    0.059616     0.006011  0.029682  0.105383   \n3                0.038847    0.059616     0.006011  0.029682  0.105383   \n4                0.040180    0.061930     0.005933  0.037142  0.102231   \n...                   ...         ...          ...       ...       ...   \n266670           0.028790    0.040797     0.001366  0.041875 -0.031260   \n266671           0.028694    0.040690     0.001415  0.043796 -0.030159   \n266672           0.029079    0.041506     0.001411  0.043666 -0.030222   \n266673           0.029203    0.041816     0.001372  0.043770 -0.028735   \n266674           0.029416    0.041948     0.001410  0.044182 -0.029418   \n\n              nz  label  \n0      -0.993818      2  \n1      -0.993904      2  \n2      -0.993989      2  \n3      -0.993989      2  \n4      -0.994067      2  \n...          ...    ...  \n266670 -0.998634      5  \n266671 -0.998585      8  \n266672 -0.998589      8  \n266673 -0.998628      8  \n266674 -0.998590      8  \n\n[266675 rows x 19 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>eigenvalue_sum</th>\n      <th>omnivariance</th>\n      <th>eigenentropy</th>\n      <th>anisotropy</th>\n      <th>planarity</th>\n      <th>linearity</th>\n      <th>PCA1</th>\n      <th>PCA2</th>\n      <th>surface_variation</th>\n      <th>sphericity</th>\n      <th>verticality</th>\n      <th>nx</th>\n      <th>ny</th>\n      <th>nz</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.001387</td>\n      <td>1.10728</td>\n      <td>0.017115</td>\n      <td>0.009678</td>\n      <td>0.001906</td>\n      <td>0.052286</td>\n      <td>0.941992</td>\n      <td>0.413554</td>\n      <td>0.528438</td>\n      <td>0.653779</td>\n      <td>0.308297</td>\n      <td>0.037924</td>\n      <td>0.058008</td>\n      <td>0.006182</td>\n      <td>0.025704</td>\n      <td>0.108003</td>\n      <td>-0.993818</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.001387</td>\n      <td>1.10974</td>\n      <td>0.017115</td>\n      <td>0.009722</td>\n      <td>0.001922</td>\n      <td>0.052496</td>\n      <td>0.941257</td>\n      <td>0.414403</td>\n      <td>0.526854</td>\n      <td>0.652789</td>\n      <td>0.308864</td>\n      <td>0.038347</td>\n      <td>0.058743</td>\n      <td>0.006097</td>\n      <td>0.027464</td>\n      <td>0.106778</td>\n      <td>-0.993904</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.001541</td>\n      <td>1.11221</td>\n      <td>0.017115</td>\n      <td>0.009777</td>\n      <td>0.001942</td>\n      <td>0.052758</td>\n      <td>0.940384</td>\n      <td>0.415397</td>\n      <td>0.524987</td>\n      <td>0.651624</td>\n      <td>0.309529</td>\n      <td>0.038847</td>\n      <td>0.059616</td>\n      <td>0.006011</td>\n      <td>0.029682</td>\n      <td>0.105383</td>\n      <td>-0.993989</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.001541</td>\n      <td>1.11221</td>\n      <td>0.017115</td>\n      <td>0.009777</td>\n      <td>0.001942</td>\n      <td>0.052758</td>\n      <td>0.940384</td>\n      <td>0.415397</td>\n      <td>0.524987</td>\n      <td>0.651624</td>\n      <td>0.309529</td>\n      <td>0.038847</td>\n      <td>0.059616</td>\n      <td>0.006011</td>\n      <td>0.029682</td>\n      <td>0.105383</td>\n      <td>-0.993989</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.003545</td>\n      <td>1.11714</td>\n      <td>0.017115</td>\n      <td>0.009984</td>\n      <td>0.002006</td>\n      <td>0.053715</td>\n      <td>0.938070</td>\n      <td>0.417451</td>\n      <td>0.520619</td>\n      <td>0.648798</td>\n      <td>0.311021</td>\n      <td>0.040180</td>\n      <td>0.061930</td>\n      <td>0.005933</td>\n      <td>0.037142</td>\n      <td>0.102231</td>\n      <td>-0.994067</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>266670</th>\n      <td>266670</td>\n      <td>1.066120</td>\n      <td>1.76079</td>\n      <td>0.021406</td>\n      <td>0.012606</td>\n      <td>0.002211</td>\n      <td>0.063959</td>\n      <td>0.959203</td>\n      <td>0.335449</td>\n      <td>0.623754</td>\n      <td>0.705695</td>\n      <td>0.265515</td>\n      <td>0.028790</td>\n      <td>0.040797</td>\n      <td>0.001366</td>\n      <td>0.041875</td>\n      <td>-0.031260</td>\n      <td>-0.998634</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>266671</th>\n      <td>266671</td>\n      <td>1.066280</td>\n      <td>1.76079</td>\n      <td>0.017115</td>\n      <td>0.012553</td>\n      <td>0.002200</td>\n      <td>0.063749</td>\n      <td>0.959310</td>\n      <td>0.336689</td>\n      <td>0.622621</td>\n      <td>0.705184</td>\n      <td>0.266122</td>\n      <td>0.028694</td>\n      <td>0.040690</td>\n      <td>0.001415</td>\n      <td>0.043796</td>\n      <td>-0.030159</td>\n      <td>-0.998585</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>266672</th>\n      <td>266672</td>\n      <td>1.066430</td>\n      <td>1.76326</td>\n      <td>0.017115</td>\n      <td>0.012362</td>\n      <td>0.002183</td>\n      <td>0.063032</td>\n      <td>0.958494</td>\n      <td>0.344354</td>\n      <td>0.614140</td>\n      <td>0.700591</td>\n      <td>0.270330</td>\n      <td>0.029079</td>\n      <td>0.041506</td>\n      <td>0.001411</td>\n      <td>0.043666</td>\n      <td>-0.030222</td>\n      <td>-0.998589</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>266673</th>\n      <td>266673</td>\n      <td>1.066430</td>\n      <td>1.76572</td>\n      <td>0.017115</td>\n      <td>0.012255</td>\n      <td>0.002170</td>\n      <td>0.062621</td>\n      <td>0.958184</td>\n      <td>0.348266</td>\n      <td>0.609918</td>\n      <td>0.698373</td>\n      <td>0.272423</td>\n      <td>0.029203</td>\n      <td>0.041816</td>\n      <td>0.001372</td>\n      <td>0.043770</td>\n      <td>-0.028735</td>\n      <td>-0.998628</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>266674</th>\n      <td>266674</td>\n      <td>1.069670</td>\n      <td>1.76326</td>\n      <td>0.017115</td>\n      <td>0.012193</td>\n      <td>0.002159</td>\n      <td>0.062339</td>\n      <td>0.958052</td>\n      <td>0.342147</td>\n      <td>0.615905</td>\n      <td>0.701241</td>\n      <td>0.269343</td>\n      <td>0.029416</td>\n      <td>0.041948</td>\n      <td>0.001410</td>\n      <td>0.044182</td>\n      <td>-0.029418</td>\n      <td>-0.998590</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>266675 rows × 19 columns</p>\n</div>"},"metadata":{}}],"execution_count":392},{"cell_type":"code","source":"points = data[['x', 'y', 'z', 'label']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.432917Z","iopub.execute_input":"2025-11-05T14:33:10.433344Z","iopub.status.idle":"2025-11-05T14:33:10.441077Z","shell.execute_reply.started":"2025-11-05T14:33:10.433312Z","shell.execute_reply":"2025-11-05T14:33:10.439746Z"}},"outputs":[],"execution_count":393},{"cell_type":"code","source":"data = data.astype(float)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.442679Z","iopub.execute_input":"2025-11-05T14:33:10.443190Z","iopub.status.idle":"2025-11-05T14:33:10.469948Z","shell.execute_reply.started":"2025-11-05T14:33:10.443150Z","shell.execute_reply":"2025-11-05T14:33:10.468725Z"}},"outputs":[],"execution_count":394},{"cell_type":"code","source":"grouped = data.groupby(data['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.471374Z","iopub.execute_input":"2025-11-05T14:33:10.471718Z","iopub.status.idle":"2025-11-05T14:33:10.477380Z","shell.execute_reply.started":"2025-11-05T14:33:10.471688Z","shell.execute_reply":"2025-11-05T14:33:10.476025Z"}},"outputs":[],"execution_count":395},{"cell_type":"code","source":"averages = grouped.mean()\nvariances = grouped.var()\naverages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.478844Z","iopub.execute_input":"2025-11-05T14:33:10.479175Z","iopub.status.idle":"2025-11-05T14:33:10.567183Z","shell.execute_reply.started":"2025-11-05T14:33:10.479149Z","shell.execute_reply":"2025-11-05T14:33:10.565989Z"}},"outputs":[{"execution_count":396,"output_type":"execute_result","data":{"text/plain":"               index         x         y         z  eigenvalue_sum  \\\nlabel                                                                \n1.0    148698.357819  0.561818  1.369313  0.017124        0.023073   \n2.0    133779.774904  0.496890  1.374248  0.017117        0.021000   \n5.0    136014.335977  0.539540  1.364338  0.064347        0.022062   \n8.0    125850.258157  0.512437  1.327641  0.041748        0.021681   \n\n       omnivariance  eigenentropy  anisotropy  planarity  linearity      PCA1  \\\nlabel                                                                           \n1.0        0.004353      0.104170    0.945872   0.485275   0.460597  0.633935   \n2.0        0.003988      0.096681    0.943492   0.461690   0.481803  0.639989   \n5.0        0.004224      0.100548    0.943282   0.447768   0.495514  0.646593   \n8.0        0.004152      0.099211    0.943478   0.456644   0.486834  0.642968   \n\n           PCA2  surface_variation  sphericity  verticality        nx  \\\nlabel                                                                   \n1.0    0.332028           0.034037    0.054128     0.003588 -0.005146   \n2.0    0.324429           0.035582    0.056508     0.004201  0.010379   \n5.0    0.317098           0.036309    0.056718     0.003879  0.005399   \n8.0    0.321184           0.035849    0.056522     0.004314  0.010231   \n\n             ny        nz  \nlabel                      \n1.0   -0.002291 -0.996412  \n2.0    0.009116 -0.995799  \n5.0   -0.002039 -0.996121  \n8.0    0.005471 -0.995686  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>eigenvalue_sum</th>\n      <th>omnivariance</th>\n      <th>eigenentropy</th>\n      <th>anisotropy</th>\n      <th>planarity</th>\n      <th>linearity</th>\n      <th>PCA1</th>\n      <th>PCA2</th>\n      <th>surface_variation</th>\n      <th>sphericity</th>\n      <th>verticality</th>\n      <th>nx</th>\n      <th>ny</th>\n      <th>nz</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.0</th>\n      <td>148698.357819</td>\n      <td>0.561818</td>\n      <td>1.369313</td>\n      <td>0.017124</td>\n      <td>0.023073</td>\n      <td>0.004353</td>\n      <td>0.104170</td>\n      <td>0.945872</td>\n      <td>0.485275</td>\n      <td>0.460597</td>\n      <td>0.633935</td>\n      <td>0.332028</td>\n      <td>0.034037</td>\n      <td>0.054128</td>\n      <td>0.003588</td>\n      <td>-0.005146</td>\n      <td>-0.002291</td>\n      <td>-0.996412</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>133779.774904</td>\n      <td>0.496890</td>\n      <td>1.374248</td>\n      <td>0.017117</td>\n      <td>0.021000</td>\n      <td>0.003988</td>\n      <td>0.096681</td>\n      <td>0.943492</td>\n      <td>0.461690</td>\n      <td>0.481803</td>\n      <td>0.639989</td>\n      <td>0.324429</td>\n      <td>0.035582</td>\n      <td>0.056508</td>\n      <td>0.004201</td>\n      <td>0.010379</td>\n      <td>0.009116</td>\n      <td>-0.995799</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>136014.335977</td>\n      <td>0.539540</td>\n      <td>1.364338</td>\n      <td>0.064347</td>\n      <td>0.022062</td>\n      <td>0.004224</td>\n      <td>0.100548</td>\n      <td>0.943282</td>\n      <td>0.447768</td>\n      <td>0.495514</td>\n      <td>0.646593</td>\n      <td>0.317098</td>\n      <td>0.036309</td>\n      <td>0.056718</td>\n      <td>0.003879</td>\n      <td>0.005399</td>\n      <td>-0.002039</td>\n      <td>-0.996121</td>\n    </tr>\n    <tr>\n      <th>8.0</th>\n      <td>125850.258157</td>\n      <td>0.512437</td>\n      <td>1.327641</td>\n      <td>0.041748</td>\n      <td>0.021681</td>\n      <td>0.004152</td>\n      <td>0.099211</td>\n      <td>0.943478</td>\n      <td>0.456644</td>\n      <td>0.486834</td>\n      <td>0.642968</td>\n      <td>0.321184</td>\n      <td>0.035849</td>\n      <td>0.056522</td>\n      <td>0.004314</td>\n      <td>0.010231</td>\n      <td>0.005471</td>\n      <td>-0.995686</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":396},{"cell_type":"code","source":"def compute_covariance_matrix(data, regularization=0):\n    cov_matrix = np.cov(data, rowvar=False)\n    cov_matrix += regularization * np.eye(cov_matrix.shape[0])\n    return cov_matrix\ndef fit(x_train, y_train):\n    y_train = y_train.ravel()\n    m = y_train.shape[0] \n    x_train = x_train.reshape(m, -1)\n    input_feature = x_train.shape[1]\n    class_label = 9\n    mu = np.zeros((class_label, input_feature))\n    sigma = np.zeros((class_label, input_feature, input_feature))\n    phi = np.zeros(class_label)\n\n    for label in range(class_label):\n        indices = (y_train == label)\n        phi[label] = float(np.sum(indices)) / m\n        mu[label] = np.mean(x_train[indices, :], axis=0)\n        sigma[label] = compute_covariance_matrix(x_train[indices, :])\n    \n    return phi, mu, sigma","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.568471Z","iopub.execute_input":"2025-11-05T14:33:10.568805Z","iopub.status.idle":"2025-11-05T14:33:10.578824Z","shell.execute_reply.started":"2025-11-05T14:33:10.568775Z","shell.execute_reply":"2025-11-05T14:33:10.577287Z"}},"outputs":[],"execution_count":397},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.580350Z","iopub.execute_input":"2025-11-05T14:33:10.580979Z","iopub.status.idle":"2025-11-05T14:33:10.602031Z","shell.execute_reply.started":"2025-11-05T14:33:10.580938Z","shell.execute_reply":"2025-11-05T14:33:10.599984Z"}},"outputs":[{"execution_count":398,"output_type":"execute_result","data":{"text/plain":"Index(['index', 'x', 'y', 'z', 'eigenvalue_sum', 'omnivariance',\n       'eigenentropy', 'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz',\n       'label'],\n      dtype='object')"},"metadata":{}}],"execution_count":398},{"cell_type":"code","source":"has_nan = data.isnull().values.any()\nhas_nan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.603717Z","iopub.execute_input":"2025-11-05T14:33:10.604526Z","iopub.status.idle":"2025-11-05T14:33:10.626777Z","shell.execute_reply.started":"2025-11-05T14:33:10.604490Z","shell.execute_reply":"2025-11-05T14:33:10.624546Z"}},"outputs":[{"execution_count":399,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":399},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.632087Z","iopub.execute_input":"2025-11-05T14:33:10.633172Z","iopub.status.idle":"2025-11-05T14:33:10.642093Z","shell.execute_reply.started":"2025-11-05T14:33:10.633134Z","shell.execute_reply":"2025-11-05T14:33:10.639991Z"}},"outputs":[{"execution_count":400,"output_type":"execute_result","data":{"text/plain":"Index(['index', 'x', 'y', 'z', 'eigenvalue_sum', 'omnivariance',\n       'eigenentropy', 'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz',\n       'label'],\n      dtype='object')"},"metadata":{}}],"execution_count":400},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ncolumns_to_scale = ['z', 'eigenvalue_sum', 'omnivariance', 'eigenentropy',\n       'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz']\n\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(data[columns_to_scale])\nscaled_df = pd.DataFrame(scaled_data, columns=columns_to_scale)\ndata[columns_to_scale] = scaled_df\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.643591Z","iopub.execute_input":"2025-11-05T14:33:10.644020Z","iopub.status.idle":"2025-11-05T14:33:10.755436Z","shell.execute_reply.started":"2025-11-05T14:33:10.643981Z","shell.execute_reply":"2025-11-05T14:33:10.753969Z"}},"outputs":[{"execution_count":401,"output_type":"execute_result","data":{"text/plain":"           index         x        y         z  eigenvalue_sum  omnivariance  \\\n0            0.0  0.001387  1.10728  0.126735        0.038009      0.045988   \n1            1.0  0.001387  1.10974  0.126735        0.039783      0.049428   \n2            2.0  0.001541  1.11221  0.126735        0.041996      0.053624   \n3            3.0  0.001541  1.11221  0.126735        0.041996      0.053624   \n4            4.0  0.003545  1.11714  0.126735        0.050290      0.067346   \n...          ...       ...      ...       ...             ...           ...   \n266670  266670.0  1.066120  1.76079  0.158510        0.155273      0.111377   \n266671  266671.0  1.066280  1.76079  0.126735        0.153173      0.109121   \n266672  266672.0  1.066430  1.76326  0.126735        0.145505      0.105410   \n266673  266673.0  1.066430  1.76572  0.126735        0.141216      0.102718   \n266674  266674.0  1.069670  1.76326  0.126735        0.138734      0.100355   \n\n        eigenentropy  anisotropy  planarity  linearity      PCA1      PCA2  \\\n0           0.044042    0.581219   0.307732   0.649447  0.495297  0.458152   \n1           0.046321    0.574475   0.308824   0.647492  0.492506  0.459861   \n2           0.049152    0.566467   0.310103   0.645188  0.489220  0.461864   \n3           0.049152    0.566467   0.310103   0.645188  0.489220  0.461864   \n4           0.059500    0.545229   0.312744   0.639796  0.481251  0.466358   \n...              ...         ...        ...        ...       ...       ...   \n266670      0.170330    0.739153   0.207270   0.767113  0.641726  0.329270   \n266671      0.168056    0.740131   0.208865   0.765714  0.640285  0.331099   \n266672      0.160299    0.732649   0.218724   0.755245  0.627332  0.343776   \n266673      0.155862    0.729799   0.223755   0.750032  0.621076  0.350081   \n266674      0.152808    0.728591   0.215885   0.757424  0.629164  0.340803   \n\n        surface_variation  sphericity  verticality        nx        ny  \\\n0                0.464719    0.418780     0.182726  0.568309  0.743198   \n1                0.471816    0.425525     0.180205  0.572416  0.740222   \n2                0.480220    0.433533     0.177689  0.577594  0.736833   \n3                0.480220    0.433533     0.177689  0.577594  0.736833   \n4                0.502621    0.454770     0.175371  0.595008  0.729176   \n...                   ...         ...          ...       ...       ...   \n266670           0.311245    0.260847     0.040384  0.606055  0.404895   \n266671           0.309631    0.259868     0.041819  0.610538  0.407570   \n266672           0.316090    0.267351     0.041708  0.610236  0.407416   \n266673           0.318187    0.270201     0.040544  0.610478  0.411029   \n266674           0.321753    0.271408     0.041670  0.611441  0.409369   \n\n              nz  label  \n0       0.182727    2.0  \n1       0.180206    2.0  \n2       0.177689    2.0  \n3       0.177689    2.0  \n4       0.175373    2.0  \n...          ...    ...  \n266670  0.040385    5.0  \n266671  0.041820    8.0  \n266672  0.041708    8.0  \n266673  0.040546    8.0  \n266674  0.041669    8.0  \n\n[266675 rows x 19 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>eigenvalue_sum</th>\n      <th>omnivariance</th>\n      <th>eigenentropy</th>\n      <th>anisotropy</th>\n      <th>planarity</th>\n      <th>linearity</th>\n      <th>PCA1</th>\n      <th>PCA2</th>\n      <th>surface_variation</th>\n      <th>sphericity</th>\n      <th>verticality</th>\n      <th>nx</th>\n      <th>ny</th>\n      <th>nz</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.001387</td>\n      <td>1.10728</td>\n      <td>0.126735</td>\n      <td>0.038009</td>\n      <td>0.045988</td>\n      <td>0.044042</td>\n      <td>0.581219</td>\n      <td>0.307732</td>\n      <td>0.649447</td>\n      <td>0.495297</td>\n      <td>0.458152</td>\n      <td>0.464719</td>\n      <td>0.418780</td>\n      <td>0.182726</td>\n      <td>0.568309</td>\n      <td>0.743198</td>\n      <td>0.182727</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.001387</td>\n      <td>1.10974</td>\n      <td>0.126735</td>\n      <td>0.039783</td>\n      <td>0.049428</td>\n      <td>0.046321</td>\n      <td>0.574475</td>\n      <td>0.308824</td>\n      <td>0.647492</td>\n      <td>0.492506</td>\n      <td>0.459861</td>\n      <td>0.471816</td>\n      <td>0.425525</td>\n      <td>0.180205</td>\n      <td>0.572416</td>\n      <td>0.740222</td>\n      <td>0.180206</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>0.001541</td>\n      <td>1.11221</td>\n      <td>0.126735</td>\n      <td>0.041996</td>\n      <td>0.053624</td>\n      <td>0.049152</td>\n      <td>0.566467</td>\n      <td>0.310103</td>\n      <td>0.645188</td>\n      <td>0.489220</td>\n      <td>0.461864</td>\n      <td>0.480220</td>\n      <td>0.433533</td>\n      <td>0.177689</td>\n      <td>0.577594</td>\n      <td>0.736833</td>\n      <td>0.177689</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>0.001541</td>\n      <td>1.11221</td>\n      <td>0.126735</td>\n      <td>0.041996</td>\n      <td>0.053624</td>\n      <td>0.049152</td>\n      <td>0.566467</td>\n      <td>0.310103</td>\n      <td>0.645188</td>\n      <td>0.489220</td>\n      <td>0.461864</td>\n      <td>0.480220</td>\n      <td>0.433533</td>\n      <td>0.177689</td>\n      <td>0.577594</td>\n      <td>0.736833</td>\n      <td>0.177689</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>0.003545</td>\n      <td>1.11714</td>\n      <td>0.126735</td>\n      <td>0.050290</td>\n      <td>0.067346</td>\n      <td>0.059500</td>\n      <td>0.545229</td>\n      <td>0.312744</td>\n      <td>0.639796</td>\n      <td>0.481251</td>\n      <td>0.466358</td>\n      <td>0.502621</td>\n      <td>0.454770</td>\n      <td>0.175371</td>\n      <td>0.595008</td>\n      <td>0.729176</td>\n      <td>0.175373</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>266670</th>\n      <td>266670.0</td>\n      <td>1.066120</td>\n      <td>1.76079</td>\n      <td>0.158510</td>\n      <td>0.155273</td>\n      <td>0.111377</td>\n      <td>0.170330</td>\n      <td>0.739153</td>\n      <td>0.207270</td>\n      <td>0.767113</td>\n      <td>0.641726</td>\n      <td>0.329270</td>\n      <td>0.311245</td>\n      <td>0.260847</td>\n      <td>0.040384</td>\n      <td>0.606055</td>\n      <td>0.404895</td>\n      <td>0.040385</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>266671</th>\n      <td>266671.0</td>\n      <td>1.066280</td>\n      <td>1.76079</td>\n      <td>0.126735</td>\n      <td>0.153173</td>\n      <td>0.109121</td>\n      <td>0.168056</td>\n      <td>0.740131</td>\n      <td>0.208865</td>\n      <td>0.765714</td>\n      <td>0.640285</td>\n      <td>0.331099</td>\n      <td>0.309631</td>\n      <td>0.259868</td>\n      <td>0.041819</td>\n      <td>0.610538</td>\n      <td>0.407570</td>\n      <td>0.041820</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>266672</th>\n      <td>266672.0</td>\n      <td>1.066430</td>\n      <td>1.76326</td>\n      <td>0.126735</td>\n      <td>0.145505</td>\n      <td>0.105410</td>\n      <td>0.160299</td>\n      <td>0.732649</td>\n      <td>0.218724</td>\n      <td>0.755245</td>\n      <td>0.627332</td>\n      <td>0.343776</td>\n      <td>0.316090</td>\n      <td>0.267351</td>\n      <td>0.041708</td>\n      <td>0.610236</td>\n      <td>0.407416</td>\n      <td>0.041708</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>266673</th>\n      <td>266673.0</td>\n      <td>1.066430</td>\n      <td>1.76572</td>\n      <td>0.126735</td>\n      <td>0.141216</td>\n      <td>0.102718</td>\n      <td>0.155862</td>\n      <td>0.729799</td>\n      <td>0.223755</td>\n      <td>0.750032</td>\n      <td>0.621076</td>\n      <td>0.350081</td>\n      <td>0.318187</td>\n      <td>0.270201</td>\n      <td>0.040544</td>\n      <td>0.610478</td>\n      <td>0.411029</td>\n      <td>0.040546</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>266674</th>\n      <td>266674.0</td>\n      <td>1.069670</td>\n      <td>1.76326</td>\n      <td>0.126735</td>\n      <td>0.138734</td>\n      <td>0.100355</td>\n      <td>0.152808</td>\n      <td>0.728591</td>\n      <td>0.215885</td>\n      <td>0.757424</td>\n      <td>0.629164</td>\n      <td>0.340803</td>\n      <td>0.321753</td>\n      <td>0.271408</td>\n      <td>0.041670</td>\n      <td>0.611441</td>\n      <td>0.409369</td>\n      <td>0.041669</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>266675 rows × 19 columns</p>\n</div>"},"metadata":{}}],"execution_count":401},{"cell_type":"code","source":"data = data.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.756691Z","iopub.execute_input":"2025-11-05T14:33:10.757147Z","iopub.status.idle":"2025-11-05T14:33:10.833661Z","shell.execute_reply.started":"2025-11-05T14:33:10.757108Z","shell.execute_reply":"2025-11-05T14:33:10.832159Z"}},"outputs":[],"execution_count":402},{"cell_type":"code","source":"# x = data[['Column1','Column2','Column3','Column4','Column5','Column6','Column7','Column8']]\nX = data[[ 'z', 'eigenvalue_sum', 'omnivariance', 'eigenentropy',\n       'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz']]\n\ny = data[['label']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.835295Z","iopub.execute_input":"2025-11-05T14:33:10.835716Z","iopub.status.idle":"2025-11-05T14:33:10.851865Z","shell.execute_reply.started":"2025-11-05T14:33:10.835677Z","shell.execute_reply":"2025-11-05T14:33:10.850432Z"}},"outputs":[],"execution_count":403},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.853800Z","iopub.execute_input":"2025-11-05T14:33:10.854245Z","iopub.status.idle":"2025-11-05T14:33:10.917147Z","shell.execute_reply.started":"2025-11-05T14:33:10.854206Z","shell.execute_reply":"2025-11-05T14:33:10.915798Z"}},"outputs":[],"execution_count":404},{"cell_type":"code","source":"X_train_values = X_train.values\ny_train_values = y_train.values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.918696Z","iopub.execute_input":"2025-11-05T14:33:10.919166Z","iopub.status.idle":"2025-11-05T14:33:10.924646Z","shell.execute_reply.started":"2025-11-05T14:33:10.919126Z","shell.execute_reply":"2025-11-05T14:33:10.923278Z"}},"outputs":[],"execution_count":405},{"cell_type":"code","source":"phi, mu, sigma = fit(X_train_values, y_train_values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:10.926210Z","iopub.execute_input":"2025-11-05T14:33:10.926532Z","iopub.status.idle":"2025-11-05T14:33:11.019497Z","shell.execute_reply.started":"2025-11-05T14:33:10.926505Z","shell.execute_reply":"2025-11-05T14:33:11.018300Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n  ret = um.true_divide(\n/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n  avg = a.mean(axis, **keepdims_kw)\n/tmp/ipykernel_33/2858995475.py:2: RuntimeWarning: Degrees of freedom <= 0 for slice\n  cov_matrix = np.cov(data, rowvar=False)\n/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n  c *= np.true_divide(1, fact)\n/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n  c *= np.true_divide(1, fact)\n","output_type":"stream"}],"execution_count":406},{"cell_type":"code","source":"phi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:11.020708Z","iopub.execute_input":"2025-11-05T14:33:11.021006Z","iopub.status.idle":"2025-11-05T14:33:11.029046Z","shell.execute_reply.started":"2025-11-05T14:33:11.020981Z","shell.execute_reply":"2025-11-05T14:33:11.027740Z"}},"outputs":[{"execution_count":407,"output_type":"execute_result","data":{"text/plain":"array([0.        , 0.14535952, 0.19212993, 0.        , 0.        ,\n       0.25900441, 0.        , 0.        , 0.40350614])"},"metadata":{}}],"execution_count":407},{"cell_type":"code","source":"for label in (1,2,5,8):\n    print(np.linalg.eigvals(sigma[label]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:11.030562Z","iopub.execute_input":"2025-11-05T14:33:11.030922Z","iopub.status.idle":"2025-11-05T14:33:11.042374Z","shell.execute_reply.started":"2025-11-05T14:33:11.030884Z","shell.execute_reply":"2025-11-05T14:33:11.041114Z"}},"outputs":[{"name":"stdout","text":"[1.65676872e-01 8.15279670e-02 3.53831486e-02 2.56213101e-02\n 1.94264800e-02 8.55207888e-03 3.83270724e-04 2.64905169e-04\n 8.69244414e-05 1.09262044e-05 5.16141477e-07 2.42230150e-13\n 4.37386119e-14 6.80965940e-16 8.00240365e-15]\n[1.38180751e-01 8.78173211e-02 4.35472107e-02 2.54698395e-02\n 1.55909389e-02 7.96228287e-03 7.51677316e-04 2.70316515e-04\n 6.86364367e-05 1.01695436e-05 1.09694808e-07 2.38931916e-13\n 4.39893329e-14 8.25919336e-15 6.40558557e-16]\n[1.54284909e-01 7.80076399e-02 5.88586027e-02 3.04656302e-02\n 2.66780195e-02 1.69529546e-02 1.29769202e-02 4.36123674e-04\n 2.10246418e-04 9.83996243e-05 9.36512688e-06 2.39363770e-13\n 4.22744136e-14 8.09334579e-15 6.80062406e-16]\n[1.39417873e-01 6.92497200e-02 4.02176136e-02 3.55013207e-02\n 2.97504708e-02 1.79738565e-02 1.41318224e-02 4.54726291e-04\n 1.89354750e-04 8.18465471e-05 1.01518603e-05 2.39057391e-13\n 4.31375664e-14 8.24447183e-15 7.03420238e-16]\n","output_type":"stream"}],"execution_count":408},{"cell_type":"code","source":"import math\ndef multivariate_gaussian_pdf(x, mean, cov):\n    d = mean.shape[0]\n    exponent = -0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(cov)), (x - mean))\n    prefactor = 1 / np.sqrt(((2 * np.pi) ** d )*(np.linalg.det(cov)))\n    return np.exp(exponent)*prefactor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:11.043628Z","iopub.execute_input":"2025-11-05T14:33:11.044106Z","iopub.status.idle":"2025-11-05T14:33:11.062302Z","shell.execute_reply.started":"2025-11-05T14:33:11.044036Z","shell.execute_reply":"2025-11-05T14:33:11.059854Z"}},"outputs":[],"execution_count":409},{"cell_type":"code","source":"def is_positive_semidefinite(matrix):\n    eigenvalues, _ = np.linalg.eig(matrix)\n    print(eigenvalues)\n    return np.all(eigenvalues >= 0)\n\nmatrix = sigma[1] \nprint(matrix)\npositive_semidefinite = is_positive_semidefinite(matrix)\nif positive_semidefinite:\n    print(\"The matrix is positive semidefinite.\")\nelse:\n    print(\"The matrix is not positive semidefinite.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:11.064325Z","iopub.execute_input":"2025-11-05T14:33:11.064693Z","iopub.status.idle":"2025-11-05T14:33:11.084225Z","shell.execute_reply.started":"2025-11-05T14:33:11.064665Z","shell.execute_reply":"2025-11-05T14:33:11.082736Z"}},"outputs":[{"name":"stdout","text":"[[ 5.23626702e-07 -2.33102894e-06 -1.98040318e-06 -2.44396850e-06\n  -3.61954006e-06  2.84591931e-06 -3.21830603e-06 -2.69053691e-06\n   2.41669711e-06  2.54906605e-06  3.61953808e-06  3.45554136e-06\n   7.98551378e-07  4.44117872e-06  3.45553192e-06]\n [-2.33102894e-06  2.32890553e-02  1.83013831e-02  2.21647424e-02\n   9.49058471e-03  1.11726349e-02 -9.44620602e-03 -6.78081909e-03\n   9.45403869e-03 -1.23350249e-02 -9.49058022e-03 -8.65975749e-03\n   7.43115737e-04  1.83774973e-03 -8.65974271e-03]\n [-1.98040318e-06  1.83013831e-02  1.89348854e-02  1.79088243e-02\n   2.36831592e-04  1.13605355e-02 -1.08714344e-02 -9.35384390e-03\n   1.04894965e-02 -2.78209130e-03 -2.36830871e-04 -6.76208671e-03\n  -2.25819393e-03  2.97452274e-03 -6.76207488e-03]\n [-2.44396850e-06  2.21647424e-02  1.79088243e-02  2.12045649e-02\n   8.25941377e-03  1.18877299e-02 -1.02981470e-02 -7.72450560e-03\n   1.02688438e-02 -1.12578249e-02 -8.25940981e-03 -8.54693883e-03\n   5.52352068e-04  1.90144598e-03 -8.54692428e-03]\n [-3.61954006e-06  9.49058471e-03  2.36831592e-04  8.25941377e-03\n   1.74448980e-02 -3.39829404e-03  5.60834900e-03  7.15833762e-03\n  -4.57028343e-03 -1.71533124e-02 -1.74448907e-02 -4.55339706e-03\n   6.26826623e-03 -2.52186241e-03 -4.55338981e-03]\n [ 2.84591931e-06  1.11726349e-02  1.13605355e-02  1.18877299e-02\n  -3.39829404e-03  4.17451948e-02 -4.05221939e-02 -3.50952284e-02\n   3.87862241e-02 -7.25951064e-03  3.39829268e-03 -7.06170255e-03\n  -2.13876404e-04 -4.41651890e-04 -7.06169121e-03]\n [-3.21830603e-06 -9.44620602e-03 -1.08714344e-02 -1.02981470e-02\n   5.60834900e-03 -4.05221939e-02  3.96457311e-02  3.46457081e-02\n  -3.78399818e-02  4.65972515e-03 -5.60834672e-03  6.16492184e-03\n   1.04852659e-03  8.46146742e-05  6.16491194e-03]\n [-2.69053691e-06 -6.78081909e-03 -9.35384390e-03 -7.72450560e-03\n   7.15833762e-03 -3.50952284e-02  3.46457081e-02  3.09160650e-02\n  -3.33130722e-02  1.62924354e-03 -7.15833466e-03  5.13212307e-03\n   1.58734066e-03 -5.81430499e-04  5.13211486e-03]\n [ 2.41669711e-06  9.45403869e-03  1.04894965e-02  1.02688438e-02\n  -4.57028343e-03  3.87862241e-02 -3.78399818e-02 -3.33130722e-02\n   3.65285517e-02 -5.28406060e-03  4.57028154e-03 -6.64935696e-03\n  -5.30325780e-04  2.04111437e-04 -6.64934632e-03]\n [ 2.54906605e-06 -1.23350249e-02 -2.78209130e-03 -1.12578249e-02\n  -1.71533124e-02 -7.25951064e-03  4.65972515e-03  1.62924354e-03\n  -5.28406060e-03  1.97662032e-02  1.71533052e-02  6.51354684e-03\n  -6.49832702e-03  2.32530932e-03  6.51353636e-03]\n [ 3.61953808e-06 -9.49058022e-03 -2.36830871e-04 -8.25940981e-03\n  -1.74448907e-02  3.39829268e-03 -5.60834672e-03 -7.15833466e-03\n   4.57028154e-03  1.71533052e-02  1.74448835e-02  4.55339515e-03\n  -6.26826360e-03  2.52186117e-03  4.55338790e-03]\n [ 3.45554136e-06 -8.65975749e-03 -6.76208671e-03 -8.54693883e-03\n  -4.55339706e-03 -7.06170255e-03  6.16492184e-03  5.13212307e-03\n  -6.64935696e-03  6.51354684e-03  4.55339515e-03  1.46442181e-02\n  -2.04783696e-03 -8.49481330e-04  1.46441949e-02]\n [ 7.98551378e-07  7.43115737e-04 -2.25819393e-03  5.52352068e-04\n   6.26826623e-03 -2.13876404e-04  1.04852659e-03  1.58734066e-03\n  -5.30325780e-04 -6.49832702e-03 -6.26826360e-03 -2.04783696e-03\n   1.33993820e-02  2.41443878e-03 -2.04783327e-03]\n [ 4.44117872e-06  1.83774973e-03  2.97452274e-03  1.90144598e-03\n  -2.52186241e-03 -4.41651890e-04  8.46146742e-05 -5.81430499e-04\n   2.04111437e-04  2.32530932e-03  2.52186117e-03 -8.49481330e-04\n   2.41443878e-03  2.73260713e-02 -8.49480642e-04]\n [ 3.45553192e-06 -8.65974271e-03 -6.76207488e-03 -8.54692428e-03\n  -4.55338981e-03 -7.06169121e-03  6.16491194e-03  5.13211486e-03\n  -6.64934632e-03  6.51353636e-03  4.55338790e-03  1.46441949e-02\n  -2.04783327e-03 -8.49480642e-04  1.46441716e-02]]\n[1.65676872e-01 8.15279670e-02 3.53831486e-02 2.56213101e-02\n 1.94264800e-02 8.55207888e-03 3.83270724e-04 2.64905169e-04\n 8.69244414e-05 1.09262044e-05 5.16141477e-07 2.42230150e-13\n 4.37386119e-14 6.80965940e-16 8.00240365e-15]\nThe matrix is positive semidefinite.\n","output_type":"stream"}],"execution_count":410},{"cell_type":"code","source":"def give_epistemic(X_test):\n    x_test = X_test.values\n    feature_densities = []\n    for i in range (x_test.shape[0]):\n        rel_probs = []\n        deno = 0\n        for label in (1,2,5,8):\n            x = multivariate_gaussian_pdf(x_test[i], mu[label], sigma[label])\n            deno += x\n            rel_probs.append(x)\n        probs = [x/deno for x in rel_probs]\n        feature_density = 0\n        labels = [1,2,5,8]\n        for j in range (len(labels)):\n            feature_density += phi[labels[j]]*probs[j]\n        feature_densities.append([x_test[i], feature_density])\n    epistemic_uncertainty = []\n    for i in feature_densities:\n        epistemic_uncertainty.append(1-i[1])\n    return epistemic_uncertainty","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:11.086083Z","iopub.execute_input":"2025-11-05T14:33:11.086604Z","iopub.status.idle":"2025-11-05T14:33:11.101110Z","shell.execute_reply.started":"2025-11-05T14:33:11.086559Z","shell.execute_reply":"2025-11-05T14:33:11.099327Z"}},"outputs":[],"execution_count":411},{"cell_type":"code","source":"def get_aleatoric(X_test, softmax_probs):\n    entropies = []\n    sum_probs = []\n    for i in range (len(softmax_probs)):\n#         sum_prob = 0\n        for j in softmax_probs[i]:\n            entropy = 0\n            if (j == 0):\n                continue\n            else:\n                entropy+= -j*np.log(j)\n#             sum_prob += j\n\n#         sum_probs.append(sum_prob)   \n        entropies.append(entropy)\n    return entropies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:11.103276Z","iopub.execute_input":"2025-11-05T14:33:11.103691Z","iopub.status.idle":"2025-11-05T14:33:11.119769Z","shell.execute_reply.started":"2025-11-05T14:33:11.103593Z","shell.execute_reply":"2025-11-05T14:33:11.118440Z"}},"outputs":[],"execution_count":412},{"cell_type":"code","source":"X_epistemic = give_epistemic(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:33:11.121781Z","iopub.execute_input":"2025-11-05T14:33:11.122200Z","iopub.status.idle":"2025-11-05T14:34:21.316303Z","shell.execute_reply.started":"2025-11-05T14:33:11.122170Z","shell.execute_reply":"2025-11-05T14:34:21.315290Z"}},"outputs":[],"execution_count":413},{"cell_type":"code","source":"# X['epistemic'] = X_epistemic\n# data_new = pd.concat([X, y], axis=1)\n# data_new = data_new.dropna()\ndata_new = data\ndata_new['epistemic'] = X_epistemic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:34:21.318676Z","iopub.execute_input":"2025-11-05T14:34:21.318985Z","iopub.status.idle":"2025-11-05T14:34:21.380266Z","shell.execute_reply.started":"2025-11-05T14:34:21.318961Z","shell.execute_reply":"2025-11-05T14:34:21.379150Z"}},"outputs":[],"execution_count":414},{"cell_type":"code","source":"X_new = data_new[['x', 'y', 'z', 'eigenvalue_sum', 'omnivariance', 'eigenentropy',\n       'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz', 'epistemic']]\n\ny_new = data_new[['label']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:34:21.381269Z","iopub.execute_input":"2025-11-05T14:34:21.381566Z","iopub.status.idle":"2025-11-05T14:34:21.418301Z","shell.execute_reply.started":"2025-11-05T14:34:21.381533Z","shell.execute_reply":"2025-11-05T14:34:21.416988Z"}},"outputs":[],"execution_count":415},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=45)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:34:21.419510Z","iopub.execute_input":"2025-11-05T14:34:21.419808Z","iopub.status.idle":"2025-11-05T14:34:21.484752Z","shell.execute_reply.started":"2025-11-05T14:34:21.419784Z","shell.execute_reply":"2025-11-05T14:34:21.483318Z"}},"outputs":[],"execution_count":416},{"cell_type":"code","source":"test_points = X_test[['x', 'y', 'z', 'epistemic']]\nX_train= X_train.drop(['x', 'y'], axis=1)\nX_test =X_test.drop(['x', 'y'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:34:21.486006Z","iopub.execute_input":"2025-11-05T14:34:21.486382Z","iopub.status.idle":"2025-11-05T14:34:21.503305Z","shell.execute_reply.started":"2025-11-05T14:34:21.486348Z","shell.execute_reply":"2025-11-05T14:34:21.502102Z"}},"outputs":[],"execution_count":417},{"cell_type":"code","source":"import numpy as np\n\ndef mean_iou(y_true, y_pred, num_classes):\n    iou_list = []\n    for c in range(num_classes):\n        tp = np.sum((y_true == c) & (y_pred == c))   # True Positives\n        fp = np.sum((y_true != c) & (y_pred == c))   # False Positives\n        fn = np.sum((y_true == c) & (y_pred != c))   # False Negatives\n\n        denom = tp + fp + fn\n        iou = tp / denom if denom != 0 else np.nan   # Avoid division by zero\n        iou_list.append(iou)\n\n    miou = np.nanmean(iou_list)  # Mean IoU (ignoring NaN)\n    return miou, iou_list\n\n\n# --- Compute mIoU on your test set ---\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:34:21.504971Z","iopub.execute_input":"2025-11-05T14:34:21.505430Z","iopub.status.idle":"2025-11-05T14:34:21.516366Z","shell.execute_reply.started":"2025-11-05T14:34:21.505391Z","shell.execute_reply":"2025-11-05T14:34:21.515125Z"}},"outputs":[],"execution_count":418},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\ndef pavpu(test_points, y_pred, y_test_mapped, k=30, accuracy_threshold=0.5, uncertainty_threshold=None):\n    points = test_points[['x', 'y', 'z']].values\n    epistemic_uncertainty = test_points[['epistemic']].values\n    y_true = np.array(y_test_mapped)\n    y_pred = np.array(y_pred)\n    nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(points)\n    _, indices = nbrs.kneighbors(points)\n    patch_acc = np.array([np.mean(y_true[idx] == y_pred[idx]) for idx in indices])\n    patch_unc = np.array([np.mean(epistemic_uncertainty[idx]) for idx in indices])\n\n    # --- Threshold patches ---\n    if uncertainty_threshold is None:\n        uncertainty_threshold = np.median(patch_unc)\n\n    accurate = patch_acc >= accuracy_threshold\n    certain = patch_unc <= uncertainty_threshold\n\n    n_ac = np.sum(accurate & certain)\n    n_au = np.sum(accurate & ~certain)\n    n_ic = np.sum(~accurate & certain)\n    n_iu = np.sum(~accurate & ~certain)\n\n    pavpu = (n_ac + n_iu) / (n_ac + n_au + n_ic + n_iu + 1e-8)\n\n    details = {\n        \"accurate_certain\": int(n_ac),\n        \"accurate_uncertain\": int(n_au),\n        \"inaccurate_certain\": int(n_ic),\n        \"inaccurate_uncertain\": int(n_iu),\n        \"uncertainty_threshold\": float(uncertainty_threshold)\n    }\n\n    return pavpu, details","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:34:21.518131Z","iopub.execute_input":"2025-11-05T14:34:21.518598Z","iopub.status.idle":"2025-11-05T14:34:21.534780Z","shell.execute_reply.started":"2025-11-05T14:34:21.518559Z","shell.execute_reply":"2025-11-05T14:34:21.533668Z"}},"outputs":[],"execution_count":419},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dropout\n\n# normalized_uncertainty = (epistemic_uncertainty - epistemic_uncertainty.min()) / (epistemic_uncertainty.max() - epistemic_uncertainty.min())\n\n# weights = 1 - normalized_uncertainty\n\nnum_classes = 4\nclasses_present = [1, 2, 5, 8]\nclass_mapping = {cls: i for i, cls in enumerate(classes_present)}\ny_mapped = y_train['label'].map(class_mapping)\ny_onehot = tf.one_hot(y_mapped, depth=num_classes)\n\n\n# Define your neural network architecture\nmodel = keras.Sequential([\n    keras.layers.Dense(128, activation='relu', input_shape=(16,)),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(4, activation='softmax') \n])\n\n# Compile the model with the custom loss function\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_onehot, epochs=10, batch_size=32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:34:21.536243Z","iopub.execute_input":"2025-11-05T14:34:21.536752Z","iopub.status.idle":"2025-11-05T14:36:19.825266Z","shell.execute_reply.started":"2025-11-05T14:34:21.536712Z","shell.execute_reply":"2025-11-05T14:36:19.823616Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.5755 - loss: 0.8552\nEpoch 2/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.6887 - loss: 0.6829\nEpoch 3/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.6311\nEpoch 4/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.5933\nEpoch 5/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.7575 - loss: 0.5711\nEpoch 6/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.7672 - loss: 0.5510\nEpoch 7/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.7742 - loss: 0.5354\nEpoch 8/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.5270\nEpoch 9/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.7850 - loss: 0.5142\nEpoch 10/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7892 - loss: 0.5058\n","output_type":"stream"},{"execution_count":420,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a1c41a8c0d0>"},"metadata":{}}],"execution_count":420},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score\n\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\ny_test_mapped = y_test['label'].map(class_mapping)\ny_test_mapped = y_test_mapped.to_numpy()\naccuracy = accuracy_score(y_test_mapped, y_pred)\n\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:36:19.829250Z","iopub.execute_input":"2025-11-05T14:36:19.829760Z","iopub.status.idle":"2025-11-05T14:36:22.941349Z","shell.execute_reply.started":"2025-11-05T14:36:19.829722Z","shell.execute_reply":"2025-11-05T14:36:22.940034Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\nTest Accuracy: 79.15%\n","output_type":"stream"}],"execution_count":421},{"cell_type":"code","source":"miou, per_class_iou = mean_iou(y_test_mapped, y_pred, num_classes=4)\n\nprint(\"IoU per class:\", per_class_iou)\nprint(\"Mean IoU:\", miou)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:36:22.942657Z","iopub.execute_input":"2025-11-05T14:36:22.943462Z","iopub.status.idle":"2025-11-05T14:36:22.952050Z","shell.execute_reply.started":"2025-11-05T14:36:22.943430Z","shell.execute_reply":"2025-11-05T14:36:22.950928Z"}},"outputs":[{"name":"stdout","text":"IoU per class: [0.5774507854444223, 0.6569099666543164, 0.7412604781123875, 0.6290725806451613]\nMean IoU: 0.6511734527140719\n","output_type":"stream"}],"execution_count":422},{"cell_type":"code","source":"pavpu_score, pavpu_details = pavpu(test_points ,y_pred, y_test_mapped)\n\nprint(\"PAvPU Score:\", pavpu_score)\nprint(\"Details:\", pavpu_details)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:36:22.953581Z","iopub.execute_input":"2025-11-05T14:36:22.954030Z","iopub.status.idle":"2025-11-05T14:36:24.582819Z","shell.execute_reply.started":"2025-11-05T14:36:22.953986Z","shell.execute_reply":"2025-11-05T14:36:24.581683Z"}},"outputs":[{"name":"stdout","text":"PAvPU Score: 0.5575138276927801\nDetails: {'accurate_certain': 25426, 'accurate_uncertain': 22358, 'inaccurate_certain': 1242, 'inaccurate_uncertain': 4309, 'uncertainty_threshold': 0.7400296225654981}\n","output_type":"stream"}],"execution_count":423},{"cell_type":"code","source":"epistemic_uncertainty = X_train['epistemic'].values\nX_train = X_train.drop(['epistemic'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:36:24.584486Z","iopub.execute_input":"2025-11-05T14:36:24.584807Z","iopub.status.idle":"2025-11-05T14:36:24.595296Z","shell.execute_reply.started":"2025-11-05T14:36:24.584780Z","shell.execute_reply":"2025-11-05T14:36:24.594117Z"}},"outputs":[],"execution_count":424},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dropout\n\nnormalized_uncertainty = (epistemic_uncertainty - epistemic_uncertainty.min()) / (epistemic_uncertainty.max() - epistemic_uncertainty.min())\n\nweights = 1 - normalized_uncertainty\n\nnum_classes = 4\nclasses_present = [1, 2, 5, 8]\nclass_mapping = {cls: i for i, cls in enumerate(classes_present)}\ny_mapped = y_train['label'].map(class_mapping)\ny_onehot = tf.one_hot(y_mapped, depth=num_classes)\n\ndef weighted_categorical_crossentropy(weights):\n    def loss(y_true, y_pred):\n        # Compute the categorical cross-entropy loss\n        cce = tf.keras.losses.CategoricalCrossentropy()\n        unweighted_loss = cce(y_true, y_pred)\n        \n        # Apply weights to the loss\n        weighted_loss = unweighted_loss * weights\n        return tf.reduce_mean(weighted_loss)\n    return loss\n\n# Define your neural network architecture\nmodel = keras.Sequential([\n    keras.layers.Dense(128, activation='relu', input_shape=(15,)),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(4, activation='softmax') \n])\n\n# Compile the model with the custom loss function\nmodel.compile(optimizer='adam', loss=weighted_categorical_crossentropy(weights),  metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_onehot, epochs=10, batch_size=32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:36:24.596625Z","iopub.execute_input":"2025-11-05T14:36:24.596990Z","iopub.status.idle":"2025-11-05T14:38:42.075848Z","shell.execute_reply.started":"2025-11-05T14:36:24.596964Z","shell.execute_reply":"2025-11-05T14:38:42.073897Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.5726 - loss: 0.3889\nEpoch 2/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.6775 - loss: 0.3113\nEpoch 3/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.7014 - loss: 0.2946\nEpoch 4/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.2813\nEpoch 5/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.2711\nEpoch 6/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.7484 - loss: 0.2620\nEpoch 7/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7552 - loss: 0.2546\nEpoch 8/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.7623 - loss: 0.2484\nEpoch 9/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.7699 - loss: 0.2423\nEpoch 10/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.2372\n","output_type":"stream"},{"execution_count":425,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a1cfb0c67d0>"},"metadata":{}}],"execution_count":425},{"cell_type":"code","source":"X_test = X_test.drop(['epistemic'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:38:42.077479Z","iopub.execute_input":"2025-11-05T14:38:42.077887Z","iopub.status.idle":"2025-11-05T14:38:42.087297Z","shell.execute_reply.started":"2025-11-05T14:38:42.077855Z","shell.execute_reply":"2025-11-05T14:38:42.085443Z"}},"outputs":[],"execution_count":426},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score\n\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\ny_test_mapped = y_test['label'].map(class_mapping)\ny_test_mapped = y_test_mapped.to_numpy()\naccuracy = accuracy_score(y_test_mapped, y_pred)\n\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:38:42.094340Z","iopub.execute_input":"2025-11-05T14:38:42.094741Z","iopub.status.idle":"2025-11-05T14:38:45.118558Z","shell.execute_reply.started":"2025-11-05T14:38:42.094703Z","shell.execute_reply":"2025-11-05T14:38:45.117401Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\nTest Accuracy: 78.57%\n","output_type":"stream"}],"execution_count":427},{"cell_type":"code","source":"miou, per_class_iou = mean_iou(y_test_mapped, y_pred, num_classes=4)\n\nprint(\"IoU per class:\", per_class_iou)\nprint(\"Mean IoU:\", miou)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:38:45.123686Z","iopub.execute_input":"2025-11-05T14:38:45.124123Z","iopub.status.idle":"2025-11-05T14:38:45.133527Z"}},"outputs":[{"name":"stdout","text":"IoU per class: [0.5747168432590427, 0.6498069498069498, 0.7314609509731461, 0.621929931392847]\nMean IoU: 0.6444786688579964\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"pavpu_score, pavpu_details = pavpu(test_points ,y_pred, y_test_mapped)\n\nprint(\"PAvPU Score:\", pavpu_score)\nprint(\"Details:\", pavpu_details)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:38:45.140944Z","iopub.execute_input":"2025-11-05T14:38:45.141333Z","iopub.status.idle":"2025-11-05T14:38:46.748022Z"}},"outputs":[{"name":"stdout","text":"PAvPU Score: 0.5580013124588811\nDetails: {'accurate_certain': 25108, 'accurate_uncertain': 22014, 'inaccurate_certain': 1560, 'inaccurate_uncertain': 4653, 'uncertainty_threshold': 0.7400296225654981}\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dropout\n\n# normalized_uncertainty = (epistemic_uncertainty - epistemic_uncertainty.min()) / (epistemic_uncertainty.max() - epistemic_uncertainty.min())\n\n# weights = 1 - normalized_uncertainty\n\nnum_classes = 4\nclasses_present = [1, 2, 5, 8]\nclass_mapping = {cls: i for i, cls in enumerate(classes_present)}\ny_mapped = y_train['label'].map(class_mapping)\ny_onehot = tf.one_hot(y_mapped, depth=num_classes)\n\n\n# Define your neural network architecture\nmodel = keras.Sequential([\n    keras.layers.Dense(128, activation='relu', input_shape=(15,)),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(4, activation='softmax') \n])\n\n# Compile the model with the custom loss function\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_onehot, epochs=10, batch_size=32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:38:46.752774Z","iopub.execute_input":"2025-11-05T14:38:46.753137Z","iopub.status.idle":"2025-11-05T14:40:58.016328Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.5731 - loss: 0.8807\nEpoch 2/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.6911 - loss: 0.6908\nEpoch 3/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6418\nEpoch 4/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.6080\nEpoch 5/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7486 - loss: 0.5887\nEpoch 6/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.7596 - loss: 0.5683\nEpoch 7/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7683 - loss: 0.5496\nEpoch 8/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.5393\nEpoch 9/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.5274\nEpoch 10/10\n\u001b[1m6667/6667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.7824 - loss: 0.5190\n","output_type":"stream"},{"execution_count":430,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a1c502596f0>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score\n\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\ny_test_mapped = y_test['label'].map(class_mapping)\ny_test_mapped = y_test_mapped.to_numpy()\naccuracy = accuracy_score(y_test_mapped, y_pred)\n\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:40:58.021259Z","iopub.execute_input":"2025-11-05T14:40:58.021583Z","iopub.status.idle":"2025-11-05T14:41:00.968970Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\nTest Accuracy: 77.97%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"miou, per_class_iou = mean_iou(y_test_mapped, y_pred, num_classes=4)\n\nprint(\"IoU per class:\", per_class_iou)\nprint(\"Mean IoU:\", miou)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:41:00.970485Z","iopub.execute_input":"2025-11-05T14:41:00.970914Z","iopub.status.idle":"2025-11-05T14:41:00.980755Z"}},"outputs":[{"name":"stdout","text":"IoU per class: [0.5450934805773515, 0.6260357971494862, 0.7222222222222222, 0.6312485989688411]\nMean IoU: 0.6311500247294752\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"pavpu_score, pavpu_details = pavpu(test_points ,y_pred, y_test_mapped)\n\nprint(\"PAvPU Score:\", pavpu_score)\nprint(\"Details:\", pavpu_details)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:41:00.982016Z","iopub.execute_input":"2025-11-05T14:41:00.982351Z","iopub.status.idle":"2025-11-05T14:41:02.627133Z"}},"outputs":[{"name":"stdout","text":"PAvPU Score: 0.5667010405923752\nDetails: {'accurate_certain': 25058, 'accurate_uncertain': 21500, 'inaccurate_certain': 1610, 'inaccurate_uncertain': 5167, 'uncertainty_threshold': 0.7400296225654981}\n","output_type":"stream"}],"execution_count":null}]}