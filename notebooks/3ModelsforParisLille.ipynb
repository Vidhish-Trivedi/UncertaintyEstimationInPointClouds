{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMODIFIED ONE - CLONED FROM THE ORIGINAL CODE\\n\\nclass_label is still 9; Since we used the 10 class model\\n\\nIf you want to run, models separately search for \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "MODIFIED ONE - CLONED FROM THE ORIGINAL CODE\n",
    "\n",
    "class_label is still 9; Since we used the 10 class model\n",
    "\n",
    "If you want to run, models separately search for \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Wait!!! Don't run the script right away..</span>\n",
    "If you want to run models separately search for #LOADPICKLESANDRUN (to save time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Import libraries>--------------||\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "#SUPPRESS WARNINGS\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the filename : features_dijon_9_interpolated_modified\n"
     ]
    }
   ],
   "source": [
    "fileName = input(\"Enter the filename :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.7 s, sys: 2.67 s, total: 9.37 s\n",
      "Wall time: 15.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>eigenvalue_sum</th>\n",
       "      <th>omnivariance</th>\n",
       "      <th>eigenentropy</th>\n",
       "      <th>anisotropy</th>\n",
       "      <th>planarity</th>\n",
       "      <th>linearity</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>surface_variation</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>verticality</th>\n",
       "      <th>nx</th>\n",
       "      <th>ny</th>\n",
       "      <th>nz</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>295.846069</td>\n",
       "      <td>91.920387</td>\n",
       "      <td>250.932510</td>\n",
       "      <td>0.031031</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.132125</td>\n",
       "      <td>0.954493</td>\n",
       "      <td>0.736989</td>\n",
       "      <td>0.217504</td>\n",
       "      <td>0.547045</td>\n",
       "      <td>0.428061</td>\n",
       "      <td>0.024894</td>\n",
       "      <td>0.045507</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>0.024083</td>\n",
       "      <td>-0.999703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>300.767090</td>\n",
       "      <td>88.947403</td>\n",
       "      <td>250.875259</td>\n",
       "      <td>0.031526</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.132059</td>\n",
       "      <td>0.985070</td>\n",
       "      <td>0.881977</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.523057</td>\n",
       "      <td>0.469134</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.014930</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.016282</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>-0.999054</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>295.196869</td>\n",
       "      <td>92.332588</td>\n",
       "      <td>250.931656</td>\n",
       "      <td>0.033873</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.140882</td>\n",
       "      <td>0.961415</td>\n",
       "      <td>0.749560</td>\n",
       "      <td>0.211855</td>\n",
       "      <td>0.547426</td>\n",
       "      <td>0.431451</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.038585</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>0.045669</td>\n",
       "      <td>-0.998593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>300.570984</td>\n",
       "      <td>89.065147</td>\n",
       "      <td>250.879089</td>\n",
       "      <td>0.031216</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.131071</td>\n",
       "      <td>0.985142</td>\n",
       "      <td>0.934722</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.509052</td>\n",
       "      <td>0.483385</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.033193</td>\n",
       "      <td>-0.999444</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>294.428955</td>\n",
       "      <td>92.836037</td>\n",
       "      <td>250.922180</td>\n",
       "      <td>0.036182</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.146512</td>\n",
       "      <td>0.962784</td>\n",
       "      <td>0.443891</td>\n",
       "      <td>0.518894</td>\n",
       "      <td>0.658622</td>\n",
       "      <td>0.316867</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>0.037216</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.069569</td>\n",
       "      <td>0.030792</td>\n",
       "      <td>-0.997102</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>9999995</td>\n",
       "      <td>384.610260</td>\n",
       "      <td>129.041702</td>\n",
       "      <td>250.336639</td>\n",
       "      <td>0.030334</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.127582</td>\n",
       "      <td>0.994352</td>\n",
       "      <td>0.925885</td>\n",
       "      <td>0.068467</td>\n",
       "      <td>0.516214</td>\n",
       "      <td>0.480870</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.005648</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>-0.026595</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>-0.999630</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>9999996</td>\n",
       "      <td>382.687256</td>\n",
       "      <td>128.930130</td>\n",
       "      <td>250.381653</td>\n",
       "      <td>0.031353</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.131220</td>\n",
       "      <td>0.989315</td>\n",
       "      <td>0.918323</td>\n",
       "      <td>0.070992</td>\n",
       "      <td>0.515546</td>\n",
       "      <td>0.478946</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>-0.045157</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>-0.998705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>9999997</td>\n",
       "      <td>384.509491</td>\n",
       "      <td>129.041916</td>\n",
       "      <td>250.331879</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.129386</td>\n",
       "      <td>0.994678</td>\n",
       "      <td>0.913555</td>\n",
       "      <td>0.081122</td>\n",
       "      <td>0.519697</td>\n",
       "      <td>0.477537</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>-0.020293</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.999790</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>9999998</td>\n",
       "      <td>382.535492</td>\n",
       "      <td>128.915543</td>\n",
       "      <td>250.393982</td>\n",
       "      <td>0.030331</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.127963</td>\n",
       "      <td>0.988894</td>\n",
       "      <td>0.880374</td>\n",
       "      <td>0.108520</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.468562</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.011106</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>-0.030470</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>-0.999293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>9999999</td>\n",
       "      <td>384.406677</td>\n",
       "      <td>129.041382</td>\n",
       "      <td>250.328018</td>\n",
       "      <td>0.030310</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.127472</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>0.968062</td>\n",
       "      <td>0.026797</td>\n",
       "      <td>0.505473</td>\n",
       "      <td>0.491928</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>-0.020859</td>\n",
       "      <td>-0.002812</td>\n",
       "      <td>-0.999778</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index           x           y           z  eigenvalue_sum  \\\n",
       "0              0  295.846069   91.920387  250.932510        0.031031   \n",
       "1              1  300.767090   88.947403  250.875259        0.031526   \n",
       "2              2  295.196869   92.332588  250.931656        0.033873   \n",
       "3              3  300.570984   89.065147  250.879089        0.031216   \n",
       "4              4  294.428955   92.836037  250.922180        0.036182   \n",
       "...          ...         ...         ...         ...             ...   \n",
       "9999995  9999995  384.610260  129.041702  250.336639        0.030334   \n",
       "9999996  9999996  382.687256  128.930130  250.381653        0.031353   \n",
       "9999997  9999997  384.509491  129.041916  250.331879        0.030908   \n",
       "9999998  9999998  382.535492  128.915543  250.393982        0.030331   \n",
       "9999999  9999999  384.406677  129.041382  250.328018        0.030310   \n",
       "\n",
       "         omnivariance  eigenentropy  anisotropy  planarity  linearity  \\\n",
       "0            0.005585      0.132125    0.954493   0.736989   0.217504   \n",
       "1            0.003916      0.132059    0.985070   0.881977   0.103093   \n",
       "2            0.005788      0.140882    0.961415   0.749560   0.211855   \n",
       "3            0.003840      0.131071    0.985142   0.934722   0.050420   \n",
       "4            0.006234      0.146512    0.962784   0.443891   0.518894   \n",
       "...               ...           ...         ...        ...        ...   \n",
       "9999995      0.002723      0.127582    0.994352   0.925885   0.068467   \n",
       "9999996      0.003474      0.131220    0.989315   0.918323   0.070992   \n",
       "9999997      0.002727      0.129386    0.994678   0.913555   0.081122   \n",
       "9999998      0.003423      0.127963    0.988894   0.880374   0.108520   \n",
       "9999999      0.002620      0.127472    0.994859   0.968062   0.026797   \n",
       "\n",
       "             PCA1      PCA2  surface_variation  sphericity  verticality  \\\n",
       "0        0.547045  0.428061           0.024894    0.045507     0.000297   \n",
       "1        0.523057  0.469134           0.007809    0.014930     0.000946   \n",
       "2        0.547426  0.431451           0.021123    0.038585     0.001407   \n",
       "3        0.509052  0.483385           0.007563    0.014858     0.000556   \n",
       "4        0.658622  0.316867           0.024511    0.037216     0.002898   \n",
       "...           ...       ...                ...         ...          ...   \n",
       "9999995  0.516214  0.480870           0.002916    0.005648     0.000370   \n",
       "9999996  0.515546  0.478946           0.005509    0.010685     0.001295   \n",
       "9999997  0.519697  0.477537           0.002766    0.005322     0.000210   \n",
       "9999998  0.525600  0.468562           0.005837    0.011106     0.000707   \n",
       "9999999  0.505473  0.491928           0.002599    0.005141     0.000222   \n",
       "\n",
       "               nx        ny        nz  label  \n",
       "0       -0.003694  0.024083 -0.999703      1  \n",
       "1        0.016282  0.040335 -0.999054      6  \n",
       "2        0.026960  0.045669 -0.998593      1  \n",
       "3        0.003012  0.033193 -0.999444      5  \n",
       "4        0.069569  0.030792 -0.997102      5  \n",
       "...           ...       ...       ...    ...  \n",
       "9999995 -0.026595  0.005652 -0.999630      9  \n",
       "9999996 -0.045157  0.023439 -0.998705      1  \n",
       "9999997 -0.020293  0.002988 -0.999790      4  \n",
       "9999998 -0.030470  0.022019 -0.999293      1  \n",
       "9999999 -0.020859 -0.002812 -0.999778      6  \n",
       "\n",
       "[10000000 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Load computed features>--------||\n",
    "data = pd.read_csv(f\"ProcessedData/{fileName}.csv\")\n",
    "\n",
    "fileName = fileName.replace(\"features_\", \"\")\n",
    "\n",
    "data = data.drop(['Unnamed: 0'], axis=1)\n",
    "data = data.dropna()\n",
    "data = data.reset_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>eigenvalue_sum</th>\n",
       "      <th>omnivariance</th>\n",
       "      <th>eigenentropy</th>\n",
       "      <th>anisotropy</th>\n",
       "      <th>planarity</th>\n",
       "      <th>linearity</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>surface_variation</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>verticality</th>\n",
       "      <th>nx</th>\n",
       "      <th>ny</th>\n",
       "      <th>nz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>4.995971e+06</td>\n",
       "      <td>350.436152</td>\n",
       "      <td>108.052458</td>\n",
       "      <td>252.694603</td>\n",
       "      <td>0.029834</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.957023</td>\n",
       "      <td>0.772169</td>\n",
       "      <td>0.184853</td>\n",
       "      <td>0.545924</td>\n",
       "      <td>0.430319</td>\n",
       "      <td>0.023757</td>\n",
       "      <td>0.042977</td>\n",
       "      <td>0.288138</td>\n",
       "      <td>-0.110579</td>\n",
       "      <td>0.147309</td>\n",
       "      <td>-0.657349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>5.000751e+06</td>\n",
       "      <td>350.494364</td>\n",
       "      <td>108.043320</td>\n",
       "      <td>252.694201</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.126903</td>\n",
       "      <td>0.956998</td>\n",
       "      <td>0.772290</td>\n",
       "      <td>0.184708</td>\n",
       "      <td>0.545853</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>0.023767</td>\n",
       "      <td>0.043002</td>\n",
       "      <td>0.288172</td>\n",
       "      <td>-0.110201</td>\n",
       "      <td>0.146474</td>\n",
       "      <td>-0.657215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>4.999758e+06</td>\n",
       "      <td>350.484692</td>\n",
       "      <td>108.053394</td>\n",
       "      <td>252.690751</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.957038</td>\n",
       "      <td>0.772449</td>\n",
       "      <td>0.184589</td>\n",
       "      <td>0.545846</td>\n",
       "      <td>0.430414</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.288297</td>\n",
       "      <td>-0.110325</td>\n",
       "      <td>0.147177</td>\n",
       "      <td>-0.656968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>4.999080e+06</td>\n",
       "      <td>350.478122</td>\n",
       "      <td>108.053923</td>\n",
       "      <td>252.691079</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.772326</td>\n",
       "      <td>0.184641</td>\n",
       "      <td>0.545801</td>\n",
       "      <td>0.430414</td>\n",
       "      <td>0.023785</td>\n",
       "      <td>0.043033</td>\n",
       "      <td>0.288336</td>\n",
       "      <td>-0.110970</td>\n",
       "      <td>0.146648</td>\n",
       "      <td>-0.657270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>5.002411e+06</td>\n",
       "      <td>350.495565</td>\n",
       "      <td>108.069653</td>\n",
       "      <td>252.694494</td>\n",
       "      <td>0.029834</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>0.126907</td>\n",
       "      <td>0.956997</td>\n",
       "      <td>0.772075</td>\n",
       "      <td>0.184922</td>\n",
       "      <td>0.545931</td>\n",
       "      <td>0.430298</td>\n",
       "      <td>0.023771</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.288595</td>\n",
       "      <td>-0.110562</td>\n",
       "      <td>0.146786</td>\n",
       "      <td>-0.656429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>4.998908e+06</td>\n",
       "      <td>350.479617</td>\n",
       "      <td>108.047473</td>\n",
       "      <td>252.694522</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.126903</td>\n",
       "      <td>0.956985</td>\n",
       "      <td>0.772149</td>\n",
       "      <td>0.184836</td>\n",
       "      <td>0.545899</td>\n",
       "      <td>0.430325</td>\n",
       "      <td>0.023776</td>\n",
       "      <td>0.043015</td>\n",
       "      <td>0.288357</td>\n",
       "      <td>-0.110741</td>\n",
       "      <td>0.147006</td>\n",
       "      <td>-0.657126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>5.005001e+06</td>\n",
       "      <td>350.528140</td>\n",
       "      <td>108.068138</td>\n",
       "      <td>252.695846</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.126922</td>\n",
       "      <td>0.957077</td>\n",
       "      <td>0.772522</td>\n",
       "      <td>0.184555</td>\n",
       "      <td>0.545817</td>\n",
       "      <td>0.430457</td>\n",
       "      <td>0.023726</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0.288486</td>\n",
       "      <td>-0.110652</td>\n",
       "      <td>0.146876</td>\n",
       "      <td>-0.656916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>4.998052e+06</td>\n",
       "      <td>350.467130</td>\n",
       "      <td>108.038044</td>\n",
       "      <td>252.695855</td>\n",
       "      <td>0.029829</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.126885</td>\n",
       "      <td>0.957079</td>\n",
       "      <td>0.772259</td>\n",
       "      <td>0.184820</td>\n",
       "      <td>0.545932</td>\n",
       "      <td>0.430345</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.042921</td>\n",
       "      <td>0.288602</td>\n",
       "      <td>-0.110473</td>\n",
       "      <td>0.146704</td>\n",
       "      <td>-0.656828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>4.999828e+06</td>\n",
       "      <td>350.481481</td>\n",
       "      <td>108.055115</td>\n",
       "      <td>252.690785</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.126909</td>\n",
       "      <td>0.957026</td>\n",
       "      <td>0.772531</td>\n",
       "      <td>0.184496</td>\n",
       "      <td>0.545781</td>\n",
       "      <td>0.430474</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>0.288388</td>\n",
       "      <td>-0.110985</td>\n",
       "      <td>0.147283</td>\n",
       "      <td>-0.657011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>5.000233e+06</td>\n",
       "      <td>350.479930</td>\n",
       "      <td>108.065507</td>\n",
       "      <td>252.689338</td>\n",
       "      <td>0.029829</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.126885</td>\n",
       "      <td>0.956976</td>\n",
       "      <td>0.771938</td>\n",
       "      <td>0.185038</td>\n",
       "      <td>0.545993</td>\n",
       "      <td>0.430220</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.043024</td>\n",
       "      <td>0.288557</td>\n",
       "      <td>-0.110862</td>\n",
       "      <td>0.146602</td>\n",
       "      <td>-0.656676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index           x           y           z  eigenvalue_sum  \\\n",
       "label                                                                     \n",
       "0.0    4.995971e+06  350.436152  108.052458  252.694603        0.029834   \n",
       "1.0    5.000751e+06  350.494364  108.043320  252.694201        0.029833   \n",
       "2.0    4.999758e+06  350.484692  108.053394  252.690751        0.029835   \n",
       "3.0    4.999080e+06  350.478122  108.053923  252.691079        0.029833   \n",
       "4.0    5.002411e+06  350.495565  108.069653  252.694494        0.029834   \n",
       "5.0    4.998908e+06  350.479617  108.047473  252.694522        0.029833   \n",
       "6.0    5.005001e+06  350.528140  108.068138  252.695846        0.029839   \n",
       "7.0    4.998052e+06  350.467130  108.038044  252.695855        0.029829   \n",
       "8.0    4.999828e+06  350.481481  108.055115  252.690785        0.029835   \n",
       "9.0    5.000233e+06  350.479930  108.065507  252.689338        0.029829   \n",
       "\n",
       "       omnivariance  eigenentropy  anisotropy  planarity  linearity      PCA1  \\\n",
       "label                                                                           \n",
       "0.0        0.004273      0.126906    0.957023   0.772169   0.184853  0.545924   \n",
       "1.0        0.004273      0.126903    0.956998   0.772290   0.184708  0.545853   \n",
       "2.0        0.004270      0.126906    0.957038   0.772449   0.184589  0.545846   \n",
       "3.0        0.004274      0.126906    0.956967   0.772326   0.184641  0.545801   \n",
       "4.0        0.004274      0.126907    0.956997   0.772075   0.184922  0.545931   \n",
       "5.0        0.004272      0.126903    0.956985   0.772149   0.184836  0.545899   \n",
       "6.0        0.004271      0.126922    0.957077   0.772522   0.184555  0.545817   \n",
       "7.0        0.004270      0.126885    0.957079   0.772259   0.184820  0.545932   \n",
       "8.0        0.004272      0.126909    0.957026   0.772531   0.184496  0.545781   \n",
       "9.0        0.004272      0.126885    0.956976   0.771938   0.185038  0.545993   \n",
       "\n",
       "           PCA2  surface_variation  sphericity  verticality        nx  \\\n",
       "label                                                                   \n",
       "0.0    0.430319           0.023757    0.042977     0.288138 -0.110579   \n",
       "1.0    0.430380           0.023767    0.043002     0.288172 -0.110201   \n",
       "2.0    0.430414           0.023740    0.042962     0.288297 -0.110325   \n",
       "3.0    0.430414           0.023785    0.043033     0.288336 -0.110970   \n",
       "4.0    0.430298           0.023771    0.043003     0.288595 -0.110562   \n",
       "5.0    0.430325           0.023776    0.043015     0.288357 -0.110741   \n",
       "6.0    0.430457           0.023726    0.042923     0.288486 -0.110652   \n",
       "7.0    0.430345           0.023723    0.042921     0.288602 -0.110473   \n",
       "8.0    0.430474           0.023745    0.042974     0.288388 -0.110985   \n",
       "9.0    0.430220           0.023787    0.043024     0.288557 -0.110862   \n",
       "\n",
       "             ny        nz  \n",
       "label                      \n",
       "0.0    0.147309 -0.657349  \n",
       "1.0    0.146474 -0.657215  \n",
       "2.0    0.147177 -0.656968  \n",
       "3.0    0.146648 -0.657270  \n",
       "4.0    0.146786 -0.656429  \n",
       "5.0    0.147006 -0.657126  \n",
       "6.0    0.146876 -0.656916  \n",
       "7.0    0.146704 -0.656828  \n",
       "8.0    0.147283 -0.657011  \n",
       "9.0    0.146602 -0.656676  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.astype(float)\n",
    "grouped = data.groupby(data['label'])\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Check distribution>------------||\n",
    "averages = grouped.mean()\n",
    "variances = grouped.var()\n",
    "averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Run from here if the Kernel is getting trashed..</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#--------------------------------------------------------------------------------------------<Import libraries>--------------||\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "#SUPPRESS WARNINGS\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "fileName = \"features_ParisLilleFullMergedData\"\n",
    "\n",
    "# Load CSV\n",
    "data = pd.read_csv(\"ProcessedData/features_ParisLilleFullMergedData.csv\")\n",
    "data = data.drop(['Unnamed: 0'], axis=1).dropna().reset_index()\n",
    "data = data.astype(float)\n",
    "\n",
    "# Group data\n",
    "grouped = data.groupby(data['label'])\n",
    "\n",
    "# Save and unload `averages`\n",
    "averages = grouped.mean()\n",
    "with open(\"tempDumps/averages.pkl\", \"wb\") as f:\n",
    "    pickle.dump(averages, f)\n",
    "del averages\n",
    "gc.collect()\n",
    "\n",
    "# Save and unload `variances`\n",
    "variances = grouped.var()\n",
    "with open(\"tempDumps/variances.pkl\", \"wb\") as f:\n",
    "    pickle.dump(variances, f)\n",
    "del variances\n",
    "gc.collect()\n",
    "\n",
    "# Save and unload `grouped`\n",
    "# Convert to dict-of-dfs before pickling\n",
    "grouped_dict = {k: v for k, v in grouped}\n",
    "with open(\"tempDumps/grouped.pkl\", \"wb\") as f:\n",
    "    pickle.dump(grouped_dict, f)\n",
    "del grouped\n",
    "del grouped_dict\n",
    "gc.collect()\n",
    "\"\"\"\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Compute cov matx>--------------||\n",
    "def compute_covariance_matrix(data, regularization=0):\n",
    "    cov_matrix = np.cov(data, rowvar=False)\n",
    "    cov_matrix += regularization * np.eye(cov_matrix.shape[0]) #Helps in computing Gaussian PDF\n",
    "    return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Get info for uncertainty est>--||\n",
    "def fit(x_train, y_train):\n",
    "    y_train = y_train.ravel()\n",
    "    m = y_train.shape[0] \n",
    "    x_train = x_train.reshape(m, -1)\n",
    "    input_feature = x_train.shape[1]\n",
    "    \n",
    "    #class_label = 9\n",
    "    class_label = 10 #ParisLille\n",
    "\n",
    "    \"\"\"\n",
    "    mu    : (μ) Denotes the population mean (Class wise mean feature vector)\n",
    "    phi   : (Φ) Prior probability of each class\n",
    "    sigma : (Σ) Covariance matrix of each class\n",
    "    \"\"\"\n",
    "    \n",
    "    mu = np.zeros((class_label, input_feature))                    # Mean vectors per class\n",
    "    sigma = np.zeros((class_label, input_feature, input_feature))  # Covariance matrices per class\n",
    "    phi = np.zeros(class_label)                                    # Prior probability per class\n",
    "\n",
    "    for label in range(class_label):\n",
    "        indices = (y_train == label)\n",
    "        phi[label] = float(np.sum(indices)) / m\n",
    "        mu[label] = np.mean(x_train[indices, :], axis=0)\n",
    "        sigma[label] = compute_covariance_matrix(x_train[indices, :])\n",
    "    \n",
    "    return phi, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'x', 'y', 'z', 'eigenvalue_sum', 'omnivariance',\n",
       "       'eigenentropy', 'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n",
       "       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_nan = data.isnull().values.any()\n",
    "print(has_nan)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Normalization : Exlcuding z (temporary, the iidea is to consider x,y for training)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>eigenvalue_sum</th>\n",
       "      <th>omnivariance</th>\n",
       "      <th>eigenentropy</th>\n",
       "      <th>anisotropy</th>\n",
       "      <th>planarity</th>\n",
       "      <th>linearity</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>surface_variation</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>verticality</th>\n",
       "      <th>nx</th>\n",
       "      <th>ny</th>\n",
       "      <th>nz</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>295.846069</td>\n",
       "      <td>91.920387</td>\n",
       "      <td>250.932510</td>\n",
       "      <td>0.509997</td>\n",
       "      <td>0.375243</td>\n",
       "      <td>0.644948</td>\n",
       "      <td>0.952301</td>\n",
       "      <td>0.739224</td>\n",
       "      <td>0.217483</td>\n",
       "      <td>0.313448</td>\n",
       "      <td>0.857417</td>\n",
       "      <td>0.076690</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.498154</td>\n",
       "      <td>0.512041</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>300.767090</td>\n",
       "      <td>88.947403</td>\n",
       "      <td>250.875259</td>\n",
       "      <td>0.518155</td>\n",
       "      <td>0.263109</td>\n",
       "      <td>0.644625</td>\n",
       "      <td>0.984351</td>\n",
       "      <td>0.884652</td>\n",
       "      <td>0.103069</td>\n",
       "      <td>0.277089</td>\n",
       "      <td>0.939687</td>\n",
       "      <td>0.024057</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.508141</td>\n",
       "      <td>0.520167</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>295.196869</td>\n",
       "      <td>92.332588</td>\n",
       "      <td>250.931656</td>\n",
       "      <td>0.556773</td>\n",
       "      <td>0.388899</td>\n",
       "      <td>0.687821</td>\n",
       "      <td>0.959556</td>\n",
       "      <td>0.751833</td>\n",
       "      <td>0.211833</td>\n",
       "      <td>0.314025</td>\n",
       "      <td>0.864209</td>\n",
       "      <td>0.065071</td>\n",
       "      <td>0.040444</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.513481</td>\n",
       "      <td>0.522835</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>300.570984</td>\n",
       "      <td>89.065147</td>\n",
       "      <td>250.879089</td>\n",
       "      <td>0.513042</td>\n",
       "      <td>0.257993</td>\n",
       "      <td>0.639783</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>0.937557</td>\n",
       "      <td>0.050394</td>\n",
       "      <td>0.255860</td>\n",
       "      <td>0.968233</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.015574</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.501507</td>\n",
       "      <td>0.516597</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>294.428955</td>\n",
       "      <td>92.836037</td>\n",
       "      <td>250.922180</td>\n",
       "      <td>0.594767</td>\n",
       "      <td>0.418888</td>\n",
       "      <td>0.715381</td>\n",
       "      <td>0.960991</td>\n",
       "      <td>0.445237</td>\n",
       "      <td>0.518880</td>\n",
       "      <td>0.482567</td>\n",
       "      <td>0.634693</td>\n",
       "      <td>0.075510</td>\n",
       "      <td>0.039009</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.534785</td>\n",
       "      <td>0.515396</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>9999995.0</td>\n",
       "      <td>384.610260</td>\n",
       "      <td>129.041702</td>\n",
       "      <td>250.336639</td>\n",
       "      <td>0.498536</td>\n",
       "      <td>0.182996</td>\n",
       "      <td>0.622706</td>\n",
       "      <td>0.994080</td>\n",
       "      <td>0.928693</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.266716</td>\n",
       "      <td>0.963196</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.486703</td>\n",
       "      <td>0.502826</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>9999996.0</td>\n",
       "      <td>382.687256</td>\n",
       "      <td>128.930130</td>\n",
       "      <td>250.381653</td>\n",
       "      <td>0.515306</td>\n",
       "      <td>0.233413</td>\n",
       "      <td>0.640517</td>\n",
       "      <td>0.988800</td>\n",
       "      <td>0.921108</td>\n",
       "      <td>0.070967</td>\n",
       "      <td>0.265703</td>\n",
       "      <td>0.959341</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.477422</td>\n",
       "      <td>0.511720</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>9999997.0</td>\n",
       "      <td>384.509491</td>\n",
       "      <td>129.041916</td>\n",
       "      <td>250.331879</td>\n",
       "      <td>0.507985</td>\n",
       "      <td>0.183201</td>\n",
       "      <td>0.631535</td>\n",
       "      <td>0.994421</td>\n",
       "      <td>0.916326</td>\n",
       "      <td>0.081097</td>\n",
       "      <td>0.271995</td>\n",
       "      <td>0.956520</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.489854</td>\n",
       "      <td>0.501494</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>9999998.0</td>\n",
       "      <td>382.535492</td>\n",
       "      <td>128.915543</td>\n",
       "      <td>250.393982</td>\n",
       "      <td>0.498486</td>\n",
       "      <td>0.230010</td>\n",
       "      <td>0.624570</td>\n",
       "      <td>0.988359</td>\n",
       "      <td>0.883044</td>\n",
       "      <td>0.108495</td>\n",
       "      <td>0.280943</td>\n",
       "      <td>0.938543</td>\n",
       "      <td>0.017983</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.484766</td>\n",
       "      <td>0.511010</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>9999999.0</td>\n",
       "      <td>384.406677</td>\n",
       "      <td>129.041382</td>\n",
       "      <td>250.328018</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.176069</td>\n",
       "      <td>0.622164</td>\n",
       "      <td>0.994611</td>\n",
       "      <td>0.970998</td>\n",
       "      <td>0.026771</td>\n",
       "      <td>0.250437</td>\n",
       "      <td>0.985345</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.489571</td>\n",
       "      <td>0.498594</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index           x           y           z  eigenvalue_sum  \\\n",
       "0              0.0  295.846069   91.920387  250.932510        0.509997   \n",
       "1              1.0  300.767090   88.947403  250.875259        0.518155   \n",
       "2              2.0  295.196869   92.332588  250.931656        0.556773   \n",
       "3              3.0  300.570984   89.065147  250.879089        0.513042   \n",
       "4              4.0  294.428955   92.836037  250.922180        0.594767   \n",
       "...            ...         ...         ...         ...             ...   \n",
       "9999995  9999995.0  384.610260  129.041702  250.336639        0.498536   \n",
       "9999996  9999996.0  382.687256  128.930130  250.381653        0.515306   \n",
       "9999997  9999997.0  384.509491  129.041916  250.331879        0.507985   \n",
       "9999998  9999998.0  382.535492  128.915543  250.393982        0.498486   \n",
       "9999999  9999999.0  384.406677  129.041382  250.328018        0.498141   \n",
       "\n",
       "         omnivariance  eigenentropy  anisotropy  planarity  linearity  \\\n",
       "0            0.375243      0.644948    0.952301   0.739224   0.217483   \n",
       "1            0.263109      0.644625    0.984351   0.884652   0.103069   \n",
       "2            0.388899      0.687821    0.959556   0.751833   0.211833   \n",
       "3            0.257993      0.639783    0.984427   0.937557   0.050394   \n",
       "4            0.418888      0.715381    0.960991   0.445237   0.518880   \n",
       "...               ...           ...         ...        ...        ...   \n",
       "9999995      0.182996      0.622706    0.994080   0.928693   0.068441   \n",
       "9999996      0.233413      0.640517    0.988800   0.921108   0.070967   \n",
       "9999997      0.183201      0.631535    0.994421   0.916326   0.081097   \n",
       "9999998      0.230010      0.624570    0.988359   0.883044   0.108495   \n",
       "9999999      0.176069      0.622164    0.994611   0.970998   0.026771   \n",
       "\n",
       "             PCA1      PCA2  surface_variation  sphericity  verticality  \\\n",
       "0        0.313448  0.857417           0.076690    0.047699     0.000297   \n",
       "1        0.277089  0.939687           0.024057    0.015649     0.000946   \n",
       "2        0.314025  0.864209           0.065071    0.040444     0.001407   \n",
       "3        0.255860  0.968233           0.023300    0.015574     0.000556   \n",
       "4        0.482567  0.634693           0.075510    0.039009     0.002898   \n",
       "...           ...       ...                ...         ...          ...   \n",
       "9999995  0.266716  0.963196           0.008982    0.005920     0.000370   \n",
       "9999996  0.265703  0.959341           0.016970    0.011200     0.001295   \n",
       "9999997  0.271995  0.956520           0.008521    0.005579     0.000210   \n",
       "9999998  0.280943  0.938543           0.017983    0.011641     0.000707   \n",
       "9999999  0.250437  0.985345           0.008005    0.005389     0.000222   \n",
       "\n",
       "               nx        ny        nz  label  \n",
       "0        0.498154  0.512041  0.000148    1.0  \n",
       "1        0.508141  0.520167  0.000473    6.0  \n",
       "2        0.513481  0.522835  0.000704    1.0  \n",
       "3        0.501507  0.516597  0.000278    5.0  \n",
       "4        0.534785  0.515396  0.001449    5.0  \n",
       "...           ...       ...       ...    ...  \n",
       "9999995  0.486703  0.502826  0.000185    9.0  \n",
       "9999996  0.477422  0.511720  0.000648    1.0  \n",
       "9999997  0.489854  0.501494  0.000105    4.0  \n",
       "9999998  0.484766  0.511010  0.000353    1.0  \n",
       "9999999  0.489571  0.498594  0.000111    6.0  \n",
       "\n",
       "[10000000 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<Nomralization>-----------------||\n",
    "from sklearn.preprocessing import MinMaxScaler #scikit-learn\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\"\"\"columns_to_scale = ['z', 'eigenvalue_sum', 'omnivariance', 'eigenentropy',\n",
    "       'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n",
    "       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz']\"\"\" #ParisLille\n",
    "\n",
    "columns_to_scale = ['eigenvalue_sum', 'omnivariance', 'eigenentropy',\n",
    "       'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n",
    "       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz'] #ParisLille, excluded z\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data[columns_to_scale])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=columns_to_scale)\n",
    "data[columns_to_scale] = scaled_df\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#FIX Memory issues\\ndel scaled_df\\ngc.collect()\\n\\ndel scaler\\ngc.collect()\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#FIX Memory issues\n",
    "del scaled_df\n",
    "gc.collect()\n",
    "\n",
    "del scaler\n",
    "gc.collect()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Prepare data>------------------||\n",
    "data = data.dropna()\n",
    "\n",
    "# x = data[['Column1','Column2','Column3','Column4','Column5','Column6','Column7','Column8']]\n",
    "\"\"\"X = data[['z', 'eigenvalue_sum', 'omnivariance', 'eigenentropy',\n",
    "       'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n",
    "       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz']]\"\"\" #ParisLille\n",
    "\n",
    "X = data[['x', 'y', 'z', 'eigenvalue_sum', 'omnivariance', 'eigenentropy',\n",
    "       'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n",
    "       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz']] #ParisLille\n",
    "\n",
    "y = data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Data split>--------------------||\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) #REVERTTHIS\n",
    "\n",
    "X_train_values = X_train.values\n",
    "y_train_values = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.82 s, sys: 258 ms, total: 3.07 s\n",
      "Wall time: 3.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1001055 , 0.1001185 , 0.09987725, 0.10021162, 0.10002563,\n",
       "       0.09985088, 0.09999763, 0.10001262, 0.09974525, 0.10005512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "phi, mu, sigma = fit(X_train_values, y_train_values)\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tempDumps/phi.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_train, f)\n",
    "\n",
    "with open(\"tempDumps/mu.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_test, f)\n",
    "\n",
    "with open(\"tempDumps/sigma.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Multivariate gaussian pdf>-----||\n",
    "import math\n",
    "def multivariate_gaussian_pdf(x, mean, cov):\n",
    "    d = mean.shape[0] #dimensionality of the input\n",
    "    exponent = -0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(cov)), (x - mean)) # -(1/2) . Transpose(x−μ) . Inverse(Σ or Covariance Matx) . (x−μ)\n",
    "    prefactor = 1 / np.sqrt(((2 * np.pi) ** d )*(np.linalg.det(cov))) # 1 / Sqrt( (2π)^d . |Σ| ) \n",
    "    return np.exp(exponent)*prefactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.90639332e+02 5.38473547e+01 1.17844858e+01 1.73728095e-01\n",
      " 8.29015041e-02 4.33279847e-02 2.41025371e-02 1.20941375e-02\n",
      " 6.18916208e-03 4.52768550e-03 1.09571006e-03 5.85247146e-04\n",
      " 8.96699074e-05 3.58369968e-06 8.28033191e-16 2.45162239e-15\n",
      " 2.38172601e-16]\n",
      "The matrix is positive semidefinite.\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<Positive semi definite chck>---||\n",
    "# Covariance matrices must be positive semidefinite because variance (and covariance) can't be negative\n",
    "def is_positive_semidefinite(matrix):\n",
    "    eigenvalues, _ = np.linalg.eig(matrix)\n",
    "    print(eigenvalues)\n",
    "    return np.all(eigenvalues >= 0)\n",
    "\n",
    "matrix = sigma[1] \n",
    "# print(matrix)\n",
    "positive_semidefinite = is_positive_semidefinite(matrix)\n",
    "if positive_semidefinite:\n",
    "    print(\"The matrix is positive semidefinite.\")\n",
    "else:\n",
    "    print(\"The matrix is not positive semidefinite.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6.27806032e+02,  3.05537804e+02,  2.24017738e+01, ...,\n",
       "         -4.87932391e-01,  5.66741724e-01,  1.42351725e+00],\n",
       "        [ 3.05537804e+02,  2.16487085e+02,  1.02267527e+01, ...,\n",
       "         -1.57626460e-01,  2.84503813e-01,  6.37775919e-01],\n",
       "        [ 2.24017738e+01,  1.02267527e+01,  1.24861894e+01, ...,\n",
       "         -1.62440636e-01,  1.98516922e-01,  5.27823376e-01],\n",
       "        ...,\n",
       "        [-4.87932391e-01, -1.57626460e-01, -1.62440636e-01, ...,\n",
       "          2.33102999e-02, -2.00559275e-02, -1.55235753e-02],\n",
       "        [ 5.66741724e-01,  2.84503813e-01,  1.98516922e-01, ...,\n",
       "         -2.00559275e-02,  4.94616677e-02,  2.16989503e-02],\n",
       "        [ 1.42351725e+00,  6.37775919e-01,  5.27823376e-01, ...,\n",
       "         -1.55235753e-02,  2.16989503e-02,  6.06404956e-02]],\n",
       "\n",
       "       [[ 6.27669228e+02,  3.05087768e+02,  2.22849154e+01, ...,\n",
       "         -4.87894080e-01,  5.69926341e-01,  1.41571416e+00],\n",
       "        [ 3.05087768e+02,  2.15974959e+02,  1.00304473e+01, ...,\n",
       "         -1.58896129e-01,  2.89871532e-01,  6.29689085e-01],\n",
       "        [ 2.22849154e+01,  1.00304473e+01,  1.24873727e+01, ...,\n",
       "         -1.59669186e-01,  1.95477096e-01,  5.26631198e-01],\n",
       "        ...,\n",
       "        [-4.87894080e-01, -1.58896129e-01, -1.59669186e-01, ...,\n",
       "          2.33339357e-02, -2.01234221e-02, -1.54073147e-02],\n",
       "        [ 5.69926341e-01,  2.89871532e-01,  1.95477096e-01, ...,\n",
       "         -2.01234221e-02,  4.95777556e-02,  2.15972418e-02],\n",
       "        [ 1.41571416e+00,  6.29689085e-01,  5.26631198e-01, ...,\n",
       "         -1.54073147e-02,  2.15972418e-02,  6.07313828e-02]],\n",
       "\n",
       "       [[ 6.26464270e+02,  3.04519112e+02,  2.21942346e+01, ...,\n",
       "         -4.84719279e-01,  5.63772843e-01,  1.41833726e+00],\n",
       "        [ 3.04519112e+02,  2.15562138e+02,  1.00223136e+01, ...,\n",
       "         -1.54031446e-01,  2.91697034e-01,  6.25039884e-01],\n",
       "        [ 2.21942346e+01,  1.00223136e+01,  1.24737525e+01, ...,\n",
       "         -1.60566208e-01,  1.97267747e-01,  5.29027984e-01],\n",
       "        ...,\n",
       "        [-4.84719279e-01, -1.54031446e-01, -1.60566208e-01, ...,\n",
       "          2.33922024e-02, -2.01316798e-02, -1.55383785e-02],\n",
       "        [ 5.63772843e-01,  2.91697034e-01,  1.97267747e-01, ...,\n",
       "         -2.01316798e-02,  4.94808136e-02,  2.17930818e-02],\n",
       "        [ 1.41833726e+00,  6.25039884e-01,  5.29027984e-01, ...,\n",
       "         -1.55383785e-02,  2.17930818e-02,  6.08438868e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 6.27331500e+02,  3.05013279e+02,  2.21612064e+01, ...,\n",
       "         -4.85149881e-01,  5.64581682e-01,  1.41630376e+00],\n",
       "        [ 3.05013279e+02,  2.16044635e+02,  1.00683859e+01, ...,\n",
       "         -1.54655867e-01,  2.81854029e-01,  6.24957986e-01],\n",
       "        [ 2.21612064e+01,  1.00683859e+01,  1.25015118e+01, ...,\n",
       "         -1.61147057e-01,  1.96618204e-01,  5.28093823e-01],\n",
       "        ...,\n",
       "        [-4.85149881e-01, -1.54655867e-01, -1.61147057e-01, ...,\n",
       "          2.34032958e-02, -2.00943447e-02, -1.55654750e-02],\n",
       "        [ 5.64581682e-01,  2.81854029e-01,  1.96618204e-01, ...,\n",
       "         -2.00943447e-02,  4.96398582e-02,  2.16587239e-02],\n",
       "        [ 1.41630376e+00,  6.24957986e-01,  5.28093823e-01, ...,\n",
       "         -1.55654750e-02,  2.16587239e-02,  6.07487006e-02]],\n",
       "\n",
       "       [[ 6.27199404e+02,  3.05092827e+02,  2.21660670e+01, ...,\n",
       "         -4.91871412e-01,  5.68482836e-01,  1.42177287e+00],\n",
       "        [ 3.05092827e+02,  2.16122632e+02,  1.00748246e+01, ...,\n",
       "         -1.57174657e-01,  2.92174284e-01,  6.29341383e-01],\n",
       "        [ 2.21660670e+01,  1.00748246e+01,  1.24193295e+01, ...,\n",
       "         -1.62190757e-01,  1.95866142e-01,  5.27214397e-01],\n",
       "        ...,\n",
       "        [-4.91871412e-01, -1.57174657e-01, -1.62190757e-01, ...,\n",
       "          2.33457612e-02, -2.00512984e-02, -1.55601390e-02],\n",
       "        [ 5.68482836e-01,  2.92174284e-01,  1.95866142e-01, ...,\n",
       "         -2.00512984e-02,  4.94798927e-02,  2.17147046e-02],\n",
       "        [ 1.42177287e+00,  6.29341383e-01,  5.27214397e-01, ...,\n",
       "         -1.55601390e-02,  2.17147046e-02,  6.06717205e-02]],\n",
       "\n",
       "       [[ 6.26683701e+02,  3.04989690e+02,  2.21146762e+01, ...,\n",
       "         -4.87639269e-01,  5.50795610e-01,  1.41707213e+00],\n",
       "        [ 3.04989690e+02,  2.16094440e+02,  1.00980967e+01, ...,\n",
       "         -1.58204937e-01,  2.79235754e-01,  6.27406779e-01],\n",
       "        [ 2.21146762e+01,  1.00980967e+01,  1.24348205e+01, ...,\n",
       "         -1.62858142e-01,  1.95744724e-01,  5.27985716e-01],\n",
       "        ...,\n",
       "        [-4.87639269e-01, -1.58204937e-01, -1.62858142e-01, ...,\n",
       "          2.33917776e-02, -2.00409398e-02, -1.55784599e-02],\n",
       "        [ 5.50795610e-01,  2.79235754e-01,  1.95744724e-01, ...,\n",
       "         -2.00409398e-02,  4.95212631e-02,  2.16159483e-02],\n",
       "        [ 1.41707213e+00,  6.27406779e-01,  5.27985716e-01, ...,\n",
       "         -1.55784599e-02,  2.16159483e-02,  6.08080837e-02]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.91243933e+02 5.38956055e+01 1.17806577e+01 1.72847442e-01\n",
      " 8.27469756e-02 4.30748218e-02 2.42039466e-02 1.20845298e-02\n",
      " 6.12164608e-03 4.51000873e-03 1.09909575e-03 5.84089130e-04\n",
      " 9.12169105e-05 3.57847703e-06 8.24219359e-16 2.47300973e-15\n",
      " 2.38895503e-16]\n",
      "[7.90639332e+02 5.38473547e+01 1.17844858e+01 1.73728095e-01\n",
      " 8.29015041e-02 4.33279847e-02 2.41025371e-02 1.20941375e-02\n",
      " 6.18916208e-03 4.52768550e-03 1.09571006e-03 5.85247146e-04\n",
      " 8.96699074e-05 3.58369968e-06 8.28033191e-16 2.45162239e-15\n",
      " 2.38172601e-16]\n",
      "[7.89133719e+02 5.37290104e+01 1.17780079e+01 1.73576705e-01\n",
      " 8.26596203e-02 4.30581028e-02 2.41120205e-02 1.21072418e-02\n",
      " 6.19752009e-03 4.49898664e-03 1.09590223e-03 5.86240585e-04\n",
      " 8.99310853e-05 3.50950822e-06 2.46871859e-15 8.92833579e-16\n",
      " 3.26482579e-16]\n",
      "[7.87630043e+02 5.40303748e+01 1.17876741e+01 1.73065086e-01\n",
      " 8.24949372e-02 4.31972408e-02 2.41181153e-02 1.21510122e-02\n",
      " 6.10185006e-03 4.55099445e-03 1.09720414e-03 5.82967614e-04\n",
      " 8.99095297e-05 3.68249469e-06 8.07923618e-16 2.45028172e-15\n",
      " 1.66222857e-16]\n",
      "[7.90246594e+02 5.40369706e+01 1.17956682e+01 1.73798920e-01\n",
      " 8.29260456e-02 4.33383184e-02 2.42070048e-02 1.20728194e-02\n",
      " 6.20186692e-03 4.51236228e-03 1.09363090e-03 5.88739061e-04\n",
      " 8.95807584e-05 3.60257204e-06 8.22286323e-16 2.47519077e-15\n",
      " 1.81660839e-16]\n",
      "[7.89891138e+02 5.38869568e+01 1.17917792e+01 1.73654260e-01\n",
      " 8.27643560e-02 4.31496274e-02 2.41681477e-02 1.22118605e-02\n",
      " 6.08319374e-03 4.55038135e-03 1.10095728e-03 5.85445871e-04\n",
      " 9.03514418e-05 3.57254080e-06 8.19404058e-16 2.44935155e-15\n",
      " 2.25126506e-16]\n",
      "[7.90324173e+02 5.38825961e+01 1.18111989e+01 1.73679542e-01\n",
      " 8.31099818e-02 4.32793507e-02 2.41514193e-02 1.21475286e-02\n",
      " 6.13411698e-03 4.56446052e-03 1.10351949e-03 5.85504043e-04\n",
      " 9.07631426e-05 3.67649730e-06 2.68402280e-16 8.56848433e-16\n",
      " 2.45036867e-15]\n",
      "[7.90304957e+02 5.38482484e+01 1.17285975e+01 1.73055021e-01\n",
      " 8.25477269e-02 4.29861529e-02 2.40305611e-02 1.21129941e-02\n",
      " 6.11934473e-03 4.52608434e-03 1.09743049e-03 5.82645257e-04\n",
      " 8.94924992e-05 3.63104198e-06 2.44749818e-15 8.42833807e-16\n",
      " 2.60528258e-16]\n",
      "[7.89809496e+02 5.37952425e+01 1.17491870e+01 1.73591216e-01\n",
      " 8.26750670e-02 4.31687799e-02 2.41745719e-02 1.21524952e-02\n",
      " 6.17891299e-03 4.52057027e-03 1.09638061e-03 5.85786424e-04\n",
      " 9.05775979e-05 3.61199829e-06 2.38947523e-15 8.33954790e-16\n",
      " 1.94939429e-16]\n"
     ]
    }
   ],
   "source": [
    "for label in (0,1,2,3,4,5,7,8,9): #ParisLille\n",
    "    print(np.linalg.eigvals(sigma[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Epistemic uncertainty calculation</span>\n",
    "Computes the epistemic uncertainty using this formula 1 − ∑ P( y=c | x )⋅ϕ(c)\n",
    "- P( y=c | x ) is class probability from the Gaussian\n",
    "- ϕ(c) is the prior (Φ, Prior probability of each class or Class prior probabilities (class frequencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Compute epistemic uncertnty>---||\n",
    "def give_epistemic(X_test):\n",
    "    x_test = X_test.values\n",
    "    feature_densities = []\n",
    "    for i in range (x_test.shape[0]):\n",
    "        rel_probs = []\n",
    "        deno = 0\n",
    "        \n",
    "        #for label in (1,2,5,8):\n",
    "        for label in (0,1,2,3,4,5,6,7,8,9): #ParisLille\n",
    "            x = multivariate_gaussian_pdf(x_test[i], mu[label], sigma[label])\n",
    "            deno += x\n",
    "            rel_probs.append(x)\n",
    "        probs = [x/deno for x in rel_probs]\n",
    "        feature_density = 0\n",
    "        \n",
    "        #labels = [1,2,5,8]\n",
    "        labels = [0,1,2,3,4,5,6,7,8,9] #ParisLille\n",
    "        for j in range (len(labels)):\n",
    "            feature_density += phi[labels[j]]*probs[j]\n",
    "        feature_densities.append([x_test[i], feature_density])\n",
    "    \n",
    "    epistemic_uncertainty = []\n",
    "    for i in feature_densities:\n",
    "        epistemic_uncertainty.append(1-i[1])\n",
    "    return epistemic_uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Aleatoric uncertainty calculation</span>\n",
    "Computes the aleatoric uncertainty using this formula Entropy(x) = −∑p_i ⋅ log(p_i). Uncertainty from softmax entropy (i.e., model's own prediction)\n",
    "- Computes entropy of the softmax output for each point\n",
    "- Higher entropy = more aleatoric uncertainty (the model is confused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Compute aleatoric uncertnty>---||\n",
    "def get_aleatoric(X_test, softmax_probs):\n",
    "    entropies = []\n",
    "    sum_probs = []\n",
    "    for i in range (len(softmax_probs)):\n",
    "        # sum_prob = 0\n",
    "        for j in softmax_probs[i]:\n",
    "            entropy = 0\n",
    "            if (j == 0):\n",
    "                continue\n",
    "            else:\n",
    "                entropy+= -j*np.log(j)\n",
    "            # sum_prob += j\n",
    "            # sum_probs.append(sum_prob)   \n",
    "        entropies.append(entropy)\n",
    "    return entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 39s, sys: 11.6 s, total: 20min 51s\n",
      "Wall time: 20min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Compute epistemic\n",
    "X_epistemic = give_epistemic(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['epistemic'] = X_epistemic\n",
    "data_new = pd.concat([X, y], axis=1)\n",
    "data_new = data_new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ProcessedData/UncertaintyAdded/fullFeatures_dijon_9_interpolated_modified.csv\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<To CSV>------------------------||\n",
    "import pickle\n",
    "\n",
    "outputPath = f\"ProcessedData/UncertaintyAdded/fullFeatures_{fileName}.csv\"\n",
    "data_new.to_csv(outputPath, index=False)\n",
    "print(f\"Data saved to {outputPath}\")\n",
    "\n",
    "with open(\"TrainTestSplitPkl/fileName.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fileName, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Load from here !!! Uncertainty estimated</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Get CSV>-----------------------||\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "with open(\"TrainTestSplitPkl/fileName.pkl\", \"rb\") as f:\n",
    "        fileName = pickle.load(f)\n",
    "\n",
    "data_new = pd.read_csv(f\"ProcessedData/UncertaintyAdded/fullFeatures_ParisLilleFullMergedData.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Prepare data>------------------||\n",
    "\"\"\"X_new = data_new[['z', 'eigenvalue_sum', 'omnivariance', 'eigenentropy',\n",
    "       'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n",
    "       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz', 'epistemic']]\"\"\"\n",
    "\n",
    "X_new = data_new[['x', 'y', 'z', 'eigenvalue_sum', 'omnivariance', 'eigenentropy',\n",
    "       'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2',\n",
    "       'surface_variation', 'sphericity', 'verticality', 'nx', 'ny', 'nz', 'epistemic']] #ParisLille, 18 including x,y\n",
    "\n",
    "y_new = data_new[['label']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=45)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2) #REVERTTHIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "\n",
    "del X_new\n",
    "gc.collect()\n",
    "\n",
    "del y_new\n",
    "gc.collect()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the data as pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pkl files to disk.\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<Save the data>-----------------||\n",
    "import pickle\n",
    "\n",
    "with open(\"TrainTestSplitPkl/X_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_train, f)\n",
    "\n",
    "with open(\"TrainTestSplitPkl/X_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_test, f)\n",
    "\n",
    "with open(\"TrainTestSplitPkl/y_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open(\"TrainTestSplitPkl/y_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_test, f)\n",
    "\n",
    "with open(\"TrainTestSplitPkl/fileName.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fileName, f)\n",
    "\n",
    "print(\"Saved pkl files to disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pickle files\n",
    "- Optional only (LOAD from here to continue with the work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Load the pickle file>----------||\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "#SUPPRESS WARNINGS\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_train, X_test, y_train, y_test, fileName = None, None, None, None, None\n",
    "\n",
    "#LOADPICKLESANDRUN\n",
    "def loadPkl():\n",
    "    with open(\"TrainTestSplitPkl/X_train.pkl\", \"rb\") as f:\n",
    "        X_train = pickle.load(f)\n",
    "    \n",
    "    with open(\"TrainTestSplitPkl/X_test.pkl\", \"rb\") as f:\n",
    "        X_test = pickle.load(f)\n",
    "    \n",
    "    with open(\"TrainTestSplitPkl/y_train.pkl\", \"rb\") as f:\n",
    "        y_train = pickle.load(f)\n",
    "    \n",
    "    with open(\"TrainTestSplitPkl/y_test.pkl\", \"rb\") as f:\n",
    "        y_test = pickle.load(f)\n",
    "    \n",
    "    with open(\"TrainTestSplitPkl/fileName.pkl\", \"rb\") as f:\n",
    "        fileName = pickle.load(f)\n",
    "    \n",
    "    print(\"Loaded pkl files from disk.\")\n",
    "    return X_train, X_test, y_train, y_test, fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pkl files from disk.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, fileName = loadPkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParisLilleFullMergedData\n"
     ]
    }
   ],
   "source": [
    "print(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:yellow\">1. Model with uncertainty as a feature</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 16:44:02.514752: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-28 16:44:02.707955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748430842.780378  465517 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748430842.801442  465517 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-28 16:44:02.984899: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1748430846.969400  465517 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13499 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748430864.892786  465723 service.cc:148] XLA service 0x7f7d64015ce0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748430864.893231  465723 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4080 SUPER, Compute Capability 8.9\n",
      "2025-05-28 16:44:24.930878: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1748430865.051377  465723 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-05-28 16:44:25.939302: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_181', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    62/748332\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31:01\u001b[0m 2ms/step - accuracy: 0.4042 - loss: 9.1424     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748430866.887501  465723 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748317/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2354   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 17:08:14.260850: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_181', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1434s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2354\n",
      "Epoch 2/3\n",
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1386s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1562\n",
      "Epoch 3/3\n",
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1383s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1505\n",
      "CPU times: user 49min 22s, sys: 23min 43s, total: 1h 13min 6s\n",
      "Wall time: 1h 10min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f7f29abfe20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Model 1 : Unc as a feature>----||\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# normalized_uncertainty = (epistemic_uncertainty - epistemic_uncertainty.min()) / (epistemic_uncertainty.max() - epistemic_uncertainty.min())\n",
    "# weights = 1 - normalized_uncertainty\n",
    "\n",
    "\"\"\"\n",
    "num_classes = 4\n",
    "classes_present = [1, 2, 5, 8]\n",
    "\"\"\"\n",
    "\n",
    "num_classes = 10\n",
    "classes_present = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] #ParisLille\n",
    "\n",
    "class_mapping = {cls: i for i, cls in enumerate(classes_present)}\n",
    "y_mapped = y_train['label'].map(class_mapping)\n",
    "y_onehot = tf.one_hot(y_mapped, depth=num_classes)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Model architecture>------------||\n",
    "model = keras.Sequential([\n",
    "    # keras.layers.Dense(128, activation='relu', input_shape=(16,)),\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(18,)), #ParisLille || 18, including x,y\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax') #keras.layers.Dense(4, activation='softmax') #ParisLille\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "model.fit(X_train, y_onehot, epochs=numEpochs, batch_size=128) #ParisLille, changed from 16 (batch size) || 64 is also a good option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 830us/step\n",
      "Test Accuracy: 95.56%\n",
      "CPU times: user 12min 58s, sys: 3min 43s, total: 16min 41s\n",
      "Wall time: 14min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Testing the model>-------------||\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_test_mapped = y_test['label'].map(class_mapping)\n",
    "y_test_mapped = y_test_mapped.to_numpy()\n",
    "accuracy = accuracy_score(y_test_mapped, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#--------------------------------------------------------------------------------------------<Load the model>----------------||\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers, models\\nfrom tensorflow import keras\\nfrom tensorflow.keras.layers import Dropout\\nfrom tensorflow.keras.models import load_model\\n\\nnumEpochs = 3\\nmodel = load_model(f\"Models/{fileName}_1_{str(numEpochs)}epoch.keras\")  # or \"my_model.h5\"\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<Save the model>----------------||\n",
    "\n",
    "# Optional: To save as a single HDF5 file instead:\n",
    "model.save(f\"Models/{fileName}_1_{str(numEpochs)}epoch.h5\")\n",
    "model.save(f\"Models/{fileName}_1_{str(numEpochs)}epoch.keras\")\n",
    "\n",
    "\"\"\"\n",
    "#--------------------------------------------------------------------------------------------<Load the model>----------------||\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "numEpochs = 3\n",
    "model = load_model(f\"Models/{fileName}_1_{str(numEpochs)}epoch.keras\")  # or \"my_model.h5\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving predicted to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------<Save the output>---------------||\n",
    "\n",
    "#Train set\n",
    "yTrainProbs = model.predict(X_train)\n",
    "yTrainPred = np.argmax(yTrainProbs, axis=1)\n",
    "\n",
    "#Test set\n",
    "yTestProbs = model.predict(X_test)\n",
    "yTestPred = np.argmax(yTestProbs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30649281\n",
      "30649281\n",
      "7662321\n",
      "7662321\n",
      "Saved merged file with 38311602 points to 'Paris_1_3epoch.csv'\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<Merge data>--------------------||\n",
    "train_df = X_train[['x', 'y', 'z']].copy()\n",
    "print(len(train_df))\n",
    "print(len(yTrainPred))\n",
    "train_df['label'] = yTrainPred\n",
    "\n",
    "test_df = X_test[['x', 'y', 'z']].copy()\n",
    "print(len(test_df))\n",
    "print(len(yTestPred))\n",
    "test_df['label'] = yTestPred\n",
    "\n",
    "combined = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "combined.to_csv(f\"Outputs/{fileName}/{fileName}_1_{str(numEpochs)}epoch.csv\", index=False)\n",
    "\n",
    "print(f\"Saved merged file with {len(combined)} points to '{fileName}_1_{str(numEpochs)}epoch.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:yellow\">2. Epistemic uncertainty + custom loss function</span>\n",
    "- #LOADPICKLESANDRUN, run this one to load the necessary files, to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadPkl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_train, X_test, y_train, y_test, fileName = \u001b[43mloadPkl\u001b[49m()\n",
      "\u001b[31mNameError\u001b[39m: name 'loadPkl' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, fileName = loadPkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epistemic_uncertainty = X_train['epistemic'].values\n",
    "X_train = X_train.drop(['epistemic'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 09:34:57.240127: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-29 09:34:57.549734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748491497.618430     747 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748491497.638216     747 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-29 09:34:57.807920: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1748491502.389827     747 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13499 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748491558.054233    2149 service.cc:148] XLA service 0x7af6180097a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748491558.054457    2149 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4080 SUPER, Compute Capability 8.9\n",
      "2025-05-29 09:35:59.340929: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1748491560.668077    2149 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-05-29 09:36:01.244627: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_202', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1748491562.125067    2149 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748326/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.1444   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 10:09:55.188926: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_202', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2072s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.1444\n",
      "Epoch 2/3\n",
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2029s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.0896\n",
      "Epoch 3/3\n",
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2025s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.0837\n",
      "CPU times: user 56min 27s, sys: 29min 40s, total: 1h 26min 7s\n",
      "Wall time: 1h 42min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7afc8eb28ee0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Model 2 : Unc + Custom loss fn>||\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "normalized_uncertainty = (epistemic_uncertainty - epistemic_uncertainty.min()) / (epistemic_uncertainty.max() - epistemic_uncertainty.min())\n",
    "\n",
    "weights = 1 - normalized_uncertainty\n",
    "\n",
    "\"\"\"\n",
    "num_classes = 4\n",
    "classes_present = [1, 2, 5, 8]\n",
    "\"\"\"\n",
    "\n",
    "num_classes = 10\n",
    "classes_present = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] #ParisLille\n",
    "class_mapping = {cls: i for i, cls in enumerate(classes_present)}\n",
    "y_mapped = y_train['label'].map(class_mapping)\n",
    "y_onehot = tf.one_hot(y_mapped, depth=num_classes)\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Compute the categorical cross-entropy loss\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "        unweighted_loss = cce(y_true, y_pred)\n",
    "        \n",
    "        # Apply weights to the loss\n",
    "        weighted_loss = unweighted_loss * weights\n",
    "        return tf.reduce_mean(weighted_loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Model architecture>------------||\n",
    "model = keras.Sequential([\n",
    "    # keras.layers.Dense(128, activation='relu', input_shape=(15,)),\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(17,)), #ParisLille\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    #keras.layers.Dense(4, activation='softmax') \n",
    "    keras.layers.Dense(10, activation='softmax') #ParisLille\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=weighted_categorical_crossentropy(weights),  metrics=['accuracy'])\n",
    "model.fit(X_train, y_onehot, epochs=numEpochs, batch_size=128) #ParisLille || batch_size=16 originally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['epistemic'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 868us/step \n",
      "Test Accuracy: 96.18%\n",
      "CPU times: user 13min 40s, sys: 4min 11s, total: 17min 51s\n",
      "Wall time: 15min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Testing the model>-------------||\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_test_mapped = y_test['label'].map(class_mapping)\n",
    "y_test_mapped = y_test_mapped.to_numpy()\n",
    "accuracy = accuracy_score(y_test_mapped, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#--------------------------------------------------------------------------------------------<Load the model>----------------//\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers, models\\nfrom tensorflow import keras\\nfrom tensorflow.keras.layers import Dropout\\nfrom tensorflow.keras.models import load_model\\n\\nnumEpochs = 3\\nmodel = load_model(f\"Models/{fileName}_2_{str(numEpochs)}epoch.keras\")  # or \"my_model.h5\"\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<Save the model>----------------||\n",
    "\n",
    "# Optional: To save as a single HDF5 file instead:\n",
    "model.save(f\"Models/{fileName}_2_{str(numEpochs)}epoch.h5\")\n",
    "model.save(f\"Models/{fileName}_2_{str(numEpochs)}epoch.keras\")\n",
    "\n",
    "\"\"\"\n",
    "#--------------------------------------------------------------------------------------------<Load the model>----------------//\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "numEpochs = 3\n",
    "model = load_model(f\"Models/{fileName}_2_{str(numEpochs)}epoch.keras\")  # or \"my_model.h5\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m957791/957791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 871us/step \n",
      "\u001b[1m239448/239448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 870us/step\n",
      "30649281\n",
      "30649281\n",
      "7662321\n",
      "7662321\n",
      "Saved merged file with 38311602 points to 'Paris_2_3epoch.csv'\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<Save the output>---------------||\n",
    "\n",
    "#Train set\n",
    "yTrainProbs = model.predict(X_train)\n",
    "yTrainPred = np.argmax(yTrainProbs, axis=1)\n",
    "\n",
    "#Test set\n",
    "yTestProbs = model.predict(X_test)\n",
    "yTestPred = np.argmax(yTestProbs, axis=1)\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Merge data>--------------------||\n",
    "train_df = X_train[['x', 'y', 'z']].copy()\n",
    "print(len(train_df))\n",
    "print(len(yTrainPred))\n",
    "train_df['label'] = yTrainPred\n",
    "\n",
    "test_df = X_test[['x', 'y', 'z']].copy()\n",
    "print(len(test_df))\n",
    "print(len(yTestPred))\n",
    "test_df['label'] = yTestPred\n",
    "\n",
    "combined = pd.concat([train_df, test_df], ignore_index=True)\n",
    "combined.to_csv(f\"Outputs/{fileName}/{fileName}_2_{str(numEpochs)}epoch.csv\", index=False)\n",
    "\n",
    "print(f\"Saved merged file with {len(combined)} points to '{fileName}_2_{str(numEpochs)}epoch.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:yellow\">3. Baseline model</span>\n",
    "- #LOADPICKLESANDRUN, run this one to load the necessary files, to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pkl files from disk.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, fileName = loadPkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>eigenvalue_sum</th>\n",
       "      <th>omnivariance</th>\n",
       "      <th>eigenentropy</th>\n",
       "      <th>anisotropy</th>\n",
       "      <th>planarity</th>\n",
       "      <th>linearity</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>surface_variation</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>verticality</th>\n",
       "      <th>nx</th>\n",
       "      <th>ny</th>\n",
       "      <th>nz</th>\n",
       "      <th>epistemic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36897033</th>\n",
       "      <td>-419.593140</td>\n",
       "      <td>-451.172577</td>\n",
       "      <td>37.803226</td>\n",
       "      <td>0.491015</td>\n",
       "      <td>0.220679</td>\n",
       "      <td>0.567044</td>\n",
       "      <td>0.982178</td>\n",
       "      <td>0.916089</td>\n",
       "      <td>0.068081</td>\n",
       "      <td>0.260952</td>\n",
       "      <td>0.956950</td>\n",
       "      <td>0.026796</td>\n",
       "      <td>0.017822</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>0.503782</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.418019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51035062</th>\n",
       "      <td>-652.800903</td>\n",
       "      <td>-638.727478</td>\n",
       "      <td>32.354855</td>\n",
       "      <td>0.507073</td>\n",
       "      <td>0.213142</td>\n",
       "      <td>0.580311</td>\n",
       "      <td>0.985311</td>\n",
       "      <td>0.944289</td>\n",
       "      <td>0.042926</td>\n",
       "      <td>0.252199</td>\n",
       "      <td>0.971742</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.014689</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.520360</td>\n",
       "      <td>0.502492</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.418019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593913</th>\n",
       "      <td>-209.249237</td>\n",
       "      <td>-297.727295</td>\n",
       "      <td>43.115593</td>\n",
       "      <td>0.479471</td>\n",
       "      <td>0.401078</td>\n",
       "      <td>0.594071</td>\n",
       "      <td>0.889519</td>\n",
       "      <td>0.671458</td>\n",
       "      <td>0.223504</td>\n",
       "      <td>0.290796</td>\n",
       "      <td>0.825524</td>\n",
       "      <td>0.173057</td>\n",
       "      <td>0.110481</td>\n",
       "      <td>0.952496</td>\n",
       "      <td>0.479484</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.523752</td>\n",
       "      <td>0.902176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62225944</th>\n",
       "      <td>-804.721375</td>\n",
       "      <td>-759.766968</td>\n",
       "      <td>26.697004</td>\n",
       "      <td>0.515548</td>\n",
       "      <td>0.140620</td>\n",
       "      <td>0.631918</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>0.952279</td>\n",
       "      <td>0.046240</td>\n",
       "      <td>0.258448</td>\n",
       "      <td>0.975606</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.498851</td>\n",
       "      <td>0.522071</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.437272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68835520</th>\n",
       "      <td>-850.011475</td>\n",
       "      <td>-817.213257</td>\n",
       "      <td>24.428015</td>\n",
       "      <td>0.550141</td>\n",
       "      <td>0.140264</td>\n",
       "      <td>0.663150</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.854960</td>\n",
       "      <td>0.144057</td>\n",
       "      <td>0.299531</td>\n",
       "      <td>0.921926</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.515624</td>\n",
       "      <td>0.521903</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.437272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847392</th>\n",
       "      <td>36.418739</td>\n",
       "      <td>81.043549</td>\n",
       "      <td>48.703979</td>\n",
       "      <td>0.332320</td>\n",
       "      <td>0.191336</td>\n",
       "      <td>0.428849</td>\n",
       "      <td>0.969498</td>\n",
       "      <td>0.370189</td>\n",
       "      <td>0.601052</td>\n",
       "      <td>0.546456</td>\n",
       "      <td>0.558971</td>\n",
       "      <td>0.062967</td>\n",
       "      <td>0.030502</td>\n",
       "      <td>0.895390</td>\n",
       "      <td>0.080022</td>\n",
       "      <td>0.766238</td>\n",
       "      <td>0.447695</td>\n",
       "      <td>0.987929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65410940</th>\n",
       "      <td>-813.928406</td>\n",
       "      <td>-783.190063</td>\n",
       "      <td>26.005972</td>\n",
       "      <td>0.510465</td>\n",
       "      <td>0.182904</td>\n",
       "      <td>0.628744</td>\n",
       "      <td>0.992937</td>\n",
       "      <td>0.971156</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.248079</td>\n",
       "      <td>0.985457</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.521947</td>\n",
       "      <td>0.503134</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.437272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78575235</th>\n",
       "      <td>-912.072083</td>\n",
       "      <td>-997.492920</td>\n",
       "      <td>21.378685</td>\n",
       "      <td>0.498952</td>\n",
       "      <td>0.220073</td>\n",
       "      <td>0.619834</td>\n",
       "      <td>0.987063</td>\n",
       "      <td>0.909224</td>\n",
       "      <td>0.079759</td>\n",
       "      <td>0.268096</td>\n",
       "      <td>0.953029</td>\n",
       "      <td>0.019643</td>\n",
       "      <td>0.012937</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.508210</td>\n",
       "      <td>0.502612</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.437272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100014494</th>\n",
       "      <td>26.126539</td>\n",
       "      <td>-529.179199</td>\n",
       "      <td>45.575958</td>\n",
       "      <td>0.483247</td>\n",
       "      <td>0.297606</td>\n",
       "      <td>0.595365</td>\n",
       "      <td>0.960109</td>\n",
       "      <td>0.719648</td>\n",
       "      <td>0.243760</td>\n",
       "      <td>0.329290</td>\n",
       "      <td>0.843765</td>\n",
       "      <td>0.064932</td>\n",
       "      <td>0.039891</td>\n",
       "      <td>0.620482</td>\n",
       "      <td>0.038622</td>\n",
       "      <td>0.533495</td>\n",
       "      <td>0.689759</td>\n",
       "      <td>0.772607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87022539</th>\n",
       "      <td>37.090584</td>\n",
       "      <td>-724.656311</td>\n",
       "      <td>44.659100</td>\n",
       "      <td>0.496999</td>\n",
       "      <td>0.219661</td>\n",
       "      <td>0.602566</td>\n",
       "      <td>0.984710</td>\n",
       "      <td>0.920964</td>\n",
       "      <td>0.066321</td>\n",
       "      <td>0.262536</td>\n",
       "      <td>0.959439</td>\n",
       "      <td>0.022921</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.504431</td>\n",
       "      <td>0.483165</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.527524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95786404 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    x           y          z  eigenvalue_sum  omnivariance  \\\n",
       "36897033  -419.593140 -451.172577  37.803226        0.491015      0.220679   \n",
       "51035062  -652.800903 -638.727478  32.354855        0.507073      0.213142   \n",
       "21593913  -209.249237 -297.727295  43.115593        0.479471      0.401078   \n",
       "62225944  -804.721375 -759.766968  26.697004        0.515548      0.140620   \n",
       "68835520  -850.011475 -817.213257  24.428015        0.550141      0.140264   \n",
       "...               ...         ...        ...             ...           ...   \n",
       "847392      36.418739   81.043549  48.703979        0.332320      0.191336   \n",
       "65410940  -813.928406 -783.190063  26.005972        0.510465      0.182904   \n",
       "78575235  -912.072083 -997.492920  21.378685        0.498952      0.220073   \n",
       "100014494   26.126539 -529.179199  45.575958        0.483247      0.297606   \n",
       "87022539    37.090584 -724.656311  44.659100        0.496999      0.219661   \n",
       "\n",
       "           eigenentropy  anisotropy  planarity  linearity      PCA1      PCA2  \\\n",
       "36897033       0.567044    0.982178   0.916089   0.068081  0.260952  0.956950   \n",
       "51035062       0.580311    0.985311   0.944289   0.042926  0.252199  0.971742   \n",
       "21593913       0.594071    0.889519   0.671458   0.223504  0.290796  0.825524   \n",
       "62225944       0.631918    0.996936   0.952279   0.046240  0.258448  0.975606   \n",
       "68835520       0.663150    0.997611   0.854960   0.144057  0.299531  0.921926   \n",
       "...                 ...         ...        ...        ...       ...       ...   \n",
       "847392         0.428849    0.969498   0.370189   0.601052  0.546456  0.558971   \n",
       "65410940       0.628744    0.992937   0.971156   0.023555  0.248079  0.985457   \n",
       "78575235       0.619834    0.987063   0.909224   0.079759  0.268096  0.953029   \n",
       "100014494      0.595365    0.960109   0.719648   0.243760  0.329290  0.843765   \n",
       "87022539       0.602566    0.984710   0.920964   0.066321  0.262536  0.959439   \n",
       "\n",
       "           surface_variation  sphericity  verticality        nx        ny  \\\n",
       "36897033            0.026796    0.017822     0.000035  0.498222  0.503782   \n",
       "51035062            0.021837    0.014689     0.000842  0.520360  0.502492   \n",
       "21593913            0.173057    0.110481     0.952496  0.479484  0.000986   \n",
       "62225944            0.004595    0.003064     0.000977  0.498851  0.522071   \n",
       "68835520            0.003773    0.002389     0.001449  0.515624  0.521903   \n",
       "...                      ...         ...          ...       ...       ...   \n",
       "847392              0.062967    0.030502     0.895390  0.080022  0.766238   \n",
       "65410940            0.010452    0.007063     0.000983  0.521947  0.503134   \n",
       "78575235            0.019643    0.012937     0.000148  0.508210  0.502612   \n",
       "100014494           0.064932    0.039891     0.620482  0.038622  0.533495   \n",
       "87022539            0.022921    0.015290     0.000606  0.504431  0.483165   \n",
       "\n",
       "                 nz  epistemic  \n",
       "36897033   0.000017   0.418019  \n",
       "51035062   0.000421   0.418019  \n",
       "21593913   0.523752   0.902176  \n",
       "62225944   0.000489   0.437272  \n",
       "68835520   0.000724   0.437272  \n",
       "...             ...        ...  \n",
       "847392     0.447695   0.987929  \n",
       "65410940   0.000492   0.437272  \n",
       "78575235   0.000074   0.437272  \n",
       "100014494  0.689759   0.772607  \n",
       "87022539   0.000303   0.527524  \n",
       "\n",
       "[95786404 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this one if needed\n",
    "X_train = X_train.drop(['epistemic'], axis=1)\n",
    "X_test = X_test.drop(['epistemic'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 18:23:16.924541: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-29 18:23:17.104424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748523197.170412  128164 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748523197.189962  128164 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-29 18:23:17.357095: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1748523201.129979  128164 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13499 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748523224.128893  128849 service.cc:148] XLA service 0x7c3f00003f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748523224.129217  128849 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4080 SUPER, Compute Capability 8.9\n",
      "2025-05-29 18:23:44.154813: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1748523224.233693  128849 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-05-29 18:23:44.744947: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_181', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    51/748332\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38:09\u001b[0m 3ms/step - accuracy: 0.3438 - loss: 17.3645    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748523225.757633  128849 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748317/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2313   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 18:47:32.490349: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_181', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1433s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2313\n",
      "Epoch 2/3\n",
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1435s\u001b[0m 2ms/step - accuracy: 0.9549 - loss: 0.1434\n",
      "Epoch 3/3\n",
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1434s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1376\n",
      "CPU times: user 52min, sys: 26min 33s, total: 1h 18min 33s\n",
      "Wall time: 1h 12min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c4501d2d0f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Model 3 : Baseline>------------||\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# normalized_uncertainty = (epistemic_uncertainty - epistemic_uncertainty.min()) / (epistemic_uncertainty.max() - epistemic_uncertainty.min())\n",
    "\n",
    "# weights = 1 - normalized_uncertainty\n",
    "\n",
    "\"\"\"\n",
    "num_classes = 4\n",
    "classes_present = [1, 2, 5, 8]\n",
    "\"\"\"\n",
    "\n",
    "num_classes = 10\n",
    "classes_present = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] #ParisLille\n",
    "class_mapping = {cls: i for i, cls in enumerate(classes_present)}\n",
    "y_mapped = y_train['label'].map(class_mapping)\n",
    "y_onehot = tf.one_hot(y_mapped, depth=num_classes)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Model architecture>------------||\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # keras.layers.Dense(128, activation='relu', input_shape=(15,)),\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(17,)), #ParisLille\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    #keras.layers.Dense(4, activation='softmax') \n",
    "    keras.layers.Dense(10, activation='softmax') #ParisLille\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "model.fit(X_train, y_onehot, epochs=numEpochs, batch_size=128) #ParisLille || batch_size=16 originally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748332/748332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 867us/step \n",
      "Test Accuracy: 96.32%\n",
      "CPU times: user 13min 33s, sys: 4min 14s, total: 17min 48s\n",
      "Wall time: 15min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Testing the model>-------------||\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_test_mapped = y_test['label'].map(class_mapping)\n",
    "y_test_mapped = y_test_mapped.to_numpy()\n",
    "accuracy = accuracy_score(y_test_mapped, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#--------------------------------------------------------------------------------------------<Load the model>----------------//\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers, models\\nfrom tensorflow import keras\\nfrom tensorflow.keras.layers import Dropout\\nfrom tensorflow.keras.models import load_model\\n\\nnumEpochs = 3\\nmodel = load_model(f\"Models/{fileName}_3_{str(numEpochs)}epoch.keras\")  # or \"my_model.h5\"\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<Save the model>----------------||\n",
    "\n",
    "# Optional: To save as a single HDF5 file instead:\n",
    "model.save(f\"Models/{fileName}_3_{str(numEpochs)}epoch.h5\")\n",
    "model.save(f\"Models/{fileName}_3_{str(numEpochs)}epoch.keras\")\n",
    "\n",
    "\"\"\"\n",
    "#--------------------------------------------------------------------------------------------<Load the model>----------------//\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "numEpochs = 3\n",
    "model = load_model(f\"Models/{fileName}_3_{str(numEpochs)}epoch.keras\")  # or \"my_model.h5\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m957791/957791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 873us/step \n",
      "\u001b[1m239448/239448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 886us/step\n",
      "30649281\n",
      "30649281\n",
      "7662321\n",
      "7662321\n",
      "Saved merged file with 38311602 points to 'Paris_3_3epoch.csv'\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------<Save the output>---------------||\n",
    "\n",
    "#Train set\n",
    "yTrainProbs = model.predict(X_train)\n",
    "yTrainPred = np.argmax(yTrainProbs, axis=1)\n",
    "\n",
    "#Test set\n",
    "yTestProbs = model.predict(X_test)\n",
    "yTestPred = np.argmax(yTestProbs, axis=1)\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------<Merge data>--------------------||\n",
    "train_df = X_train[['x', 'y', 'z']].copy()\n",
    "print(len(train_df))\n",
    "print(len(yTrainPred))\n",
    "train_df['label'] = yTrainPred\n",
    "\n",
    "test_df = X_test[['x', 'y', 'z']].copy()\n",
    "print(len(test_df))\n",
    "print(len(yTestPred))\n",
    "test_df['label'] = yTestPred\n",
    "\n",
    "combined = pd.concat([train_df, test_df], ignore_index=True)\n",
    "combined.to_csv(f\"Outputs/{fileName}/{fileName}_3_{str(numEpochs)}epoch.csv\", index=False)\n",
    "\n",
    "print(f\"Saved merged file with {len(combined)} points to '{fileName}_3_{str(numEpochs)}epoch.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5385235,
     "sourceId": 8948890,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5416828,
     "sourceId": 8993126,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5416980,
     "sourceId": 8993346,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5482927,
     "sourceId": 9086944,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5483938,
     "sourceId": 9088327,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5484469,
     "sourceId": 9089052,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5484754,
     "sourceId": 9089444,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5506630,
     "sourceId": 9121936,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
