{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Feature Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Dataset With Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = \"1point0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>//X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Scalar field</th>\n",
       "      <th>Eigenvalues sum (1)</th>\n",
       "      <th>Omnivariance (1)</th>\n",
       "      <th>Eigenentropy (1)</th>\n",
       "      <th>Anisotropy (1)</th>\n",
       "      <th>Planarity (1)</th>\n",
       "      <th>Linearity (1)</th>\n",
       "      <th>Sphericity (1)</th>\n",
       "      <th>Verticality (1)</th>\n",
       "      <th>Nx</th>\n",
       "      <th>Ny</th>\n",
       "      <th>Nz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>1.10728</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10524</td>\n",
       "      <td>0.01319</td>\n",
       "      <td>0.31369</td>\n",
       "      <td>0.98523</td>\n",
       "      <td>0.79733</td>\n",
       "      <td>0.18790</td>\n",
       "      <td>0.01477</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.125512</td>\n",
       "      <td>0.992091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>1.10974</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10538</td>\n",
       "      <td>0.01320</td>\n",
       "      <td>0.31396</td>\n",
       "      <td>0.98526</td>\n",
       "      <td>0.79686</td>\n",
       "      <td>0.18839</td>\n",
       "      <td>0.01474</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.081042</td>\n",
       "      <td>0.996710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001541</td>\n",
       "      <td>1.11221</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10552</td>\n",
       "      <td>0.01321</td>\n",
       "      <td>0.31424</td>\n",
       "      <td>0.98528</td>\n",
       "      <td>0.79624</td>\n",
       "      <td>0.18904</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.081042</td>\n",
       "      <td>0.996710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001541</td>\n",
       "      <td>1.11221</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10552</td>\n",
       "      <td>0.01321</td>\n",
       "      <td>0.31424</td>\n",
       "      <td>0.98528</td>\n",
       "      <td>0.79624</td>\n",
       "      <td>0.18904</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.081042</td>\n",
       "      <td>0.996710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003545</td>\n",
       "      <td>1.11714</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10593</td>\n",
       "      <td>0.01324</td>\n",
       "      <td>0.31502</td>\n",
       "      <td>0.98535</td>\n",
       "      <td>0.79561</td>\n",
       "      <td>0.18974</td>\n",
       "      <td>0.01465</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.697373</td>\n",
       "      <td>0.716707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        //X        Y         Z  Scalar field  Eigenvalues sum (1)  \\\n",
       "0  0.001387  1.10728  0.017115           2.0              0.10524   \n",
       "1  0.001387  1.10974  0.017115           2.0              0.10538   \n",
       "2  0.001541  1.11221  0.017115           2.0              0.10552   \n",
       "3  0.001541  1.11221  0.017115           2.0              0.10552   \n",
       "4  0.003545  1.11714  0.017115           2.0              0.10593   \n",
       "\n",
       "   Omnivariance (1)  Eigenentropy (1)  Anisotropy (1)  Planarity (1)  \\\n",
       "0           0.01319           0.31369         0.98523        0.79733   \n",
       "1           0.01320           0.31396         0.98526        0.79686   \n",
       "2           0.01321           0.31424         0.98528        0.79624   \n",
       "3           0.01321           0.31424         0.98528        0.79624   \n",
       "4           0.01324           0.31502         0.98535        0.79561   \n",
       "\n",
       "   Linearity (1)  Sphericity (1)  Verticality (1)        Nx        Ny  \\\n",
       "0        0.18790         0.01477          0.00002  0.001091  0.125512   \n",
       "1        0.18839         0.01474          0.00002  0.001052  0.081042   \n",
       "2        0.18904         0.01472          0.00002  0.001052  0.081042   \n",
       "3        0.18904         0.01472          0.00002  0.001052  0.081042   \n",
       "4        0.18974         0.01465          0.00002  0.001381  0.697373   \n",
       "\n",
       "         Nz  \n",
       "0  0.992091  \n",
       "1  0.996710  \n",
       "2  0.996710  \n",
       "3  0.996710  \n",
       "4  0.716707  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = f\"CloudCompare/area2_cov_multi-nbd-{scale}-features.csv\"\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['x', 'y', 'z', 'class', 'eigenvalues_sum', 'omnivariance', 'eigentropy', 'anisotropy', 'linearity', 'sphericity', 'planarity', 'verticality']\n",
    "geometric_features = ['eigenvalues_sum', 'omnivariance', 'eigentropy', 'anisotropy', 'linearity', 'sphericity', 'planarity', 'verticality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = f\"({scale.split('point')[0] + '.' + scale.split('point')[1]})\"\n",
    "if scale == \"(1.0)\":\n",
    "    scale = \"(1)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'//X': 'x', 'Y': 'y', 'Z': 'z', 'Scalar field': 'class', f\"Eigenvalues sum {scale}\": 'eigenvalues_sum', f\"Omnivariance {scale}\": 'omnivariance', f\"Eigenentropy {scale}\": 'eigentropy', f\"Anisotropy {scale}\": 'anisotropy', f\"Linearity {scale}\": 'linearity', f\"Sphericity {scale}\": 'sphericity', f\"Planarity {scale}\": 'planarity', f\"Verticality {scale}\": 'verticality'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the percentage of null values in each column\n",
    "def print_null_percentage(df):\n",
    "    total_rows = len(df)\n",
    "    for column in df.columns:\n",
    "        null_count = df[column].isnull().sum()\n",
    "        percentage_null = (null_count / total_rows) * 100\n",
    "        print(f\"Column '{column}': {percentage_null:.2f}% null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'x': 0.00% null values\n",
      "Column 'y': 0.00% null values\n",
      "Column 'z': 0.00% null values\n",
      "Column 'class': 0.00% null values\n",
      "Column 'eigenvalues_sum': 0.00% null values\n",
      "Column 'omnivariance': 0.00% null values\n",
      "Column 'eigentropy': 0.00% null values\n",
      "Column 'anisotropy': 0.00% null values\n",
      "Column 'planarity': 0.00% null values\n",
      "Column 'linearity': 0.00% null values\n",
      "Column 'sphericity': 0.00% null values\n",
      "Column 'verticality': 0.00% null values\n",
      "Column 'Nx': 0.00% null values\n",
      "Column 'Ny': 0.00% null values\n",
      "Column 'Nz': 0.00% null values\n"
     ]
    }
   ],
   "source": [
    "print_null_percentage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Nx', 'Ny', 'Nz'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Class-Wise Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>eigenvalues_sum</th>\n",
       "      <th>omnivariance</th>\n",
       "      <th>eigentropy</th>\n",
       "      <th>anisotropy</th>\n",
       "      <th>planarity</th>\n",
       "      <th>linearity</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>verticality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.561818</td>\n",
       "      <td>1.369313</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.014106</td>\n",
       "      <td>0.339354</td>\n",
       "      <td>0.988357</td>\n",
       "      <td>0.669069</td>\n",
       "      <td>0.319281</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.496890</td>\n",
       "      <td>1.374248</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>0.118266</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.336603</td>\n",
       "      <td>0.988134</td>\n",
       "      <td>0.672568</td>\n",
       "      <td>0.315561</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.539540</td>\n",
       "      <td>1.364338</td>\n",
       "      <td>0.064347</td>\n",
       "      <td>0.119638</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.339064</td>\n",
       "      <td>0.988342</td>\n",
       "      <td>0.668385</td>\n",
       "      <td>0.319950</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.512437</td>\n",
       "      <td>1.327641</td>\n",
       "      <td>0.041748</td>\n",
       "      <td>0.119446</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.338741</td>\n",
       "      <td>0.988311</td>\n",
       "      <td>0.669778</td>\n",
       "      <td>0.318527</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x         y         z  eigenvalues_sum  omnivariance  \\\n",
       "class                                                                \n",
       "1.0    0.561818  1.369313  0.017125         0.119789      0.014106   \n",
       "2.0    0.496890  1.374248  0.017118         0.118266      0.014000   \n",
       "5.0    0.539540  1.364338  0.064347         0.119638      0.014094   \n",
       "8.0    0.512437  1.327641  0.041748         0.119446      0.014082   \n",
       "\n",
       "       eigentropy  anisotropy  planarity  linearity  sphericity  verticality  \n",
       "class                                                                         \n",
       "1.0      0.339354    0.988357   0.669069   0.319281    0.011643     0.000034  \n",
       "2.0      0.336603    0.988134   0.672568   0.315561    0.011866     0.000040  \n",
       "5.0      0.339064    0.988342   0.668385   0.319950    0.011658     0.000034  \n",
       "8.0      0.338741    0.988311   0.669778   0.318527    0.011689     0.000033  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = data.groupby(data['class'])\n",
    "averages = grouped.mean()\n",
    "variances = grouped.var()\n",
    "averages\n",
    "# variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the covariance matrix\n",
    "def compute_covariance_matrix(data, regularization=0):\n",
    "    cov_matrix = np.cov(data, rowvar=False)\n",
    "    cov_matrix += regularization * np.eye(cov_matrix.shape[0])\n",
    "    return cov_matrix\n",
    "\n",
    "# Function to fit the model\n",
    "def fit(x_train, y_train):\n",
    "    y_train = y_train.ravel()\n",
    "    m = y_train.shape[0] \n",
    "    x_train = x_train.reshape(m, -1)\n",
    "    input_feature = x_train.shape[1] # Number of input feature. In our case it's 4\n",
    "    class_label = 9\n",
    "    mu = np.zeros((class_label, input_feature))\n",
    "    sigma = np.zeros((class_label, input_feature, input_feature))\n",
    "    phi = np.zeros(class_label)\n",
    "\n",
    "    for label in range(class_label):\n",
    "        # Seperate all the training data for a single class\n",
    "        indices = (y_train == label)\n",
    "        \n",
    "        phi[label] = float(np.sum(indices)) / m\n",
    "        mu[label] = np.mean(x_train[indices, :], axis=0)\n",
    "        # Instead of writting the equation we used numpy covariance function. \n",
    "        sigma[label] = compute_covariance_matrix(x_train[indices, :])\n",
    "    \n",
    "    return phi, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping any null values\n",
    "# data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting The Gaussian Discriminant Analysis (GDA) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[geometric_features]\n",
    "y = data[['class']]\n",
    "\n",
    "x = x.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266675, 12)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vidhish17\\Desktop\\RE\\gvcl\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Vidhish17\\Desktop\\RE\\gvcl\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\Vidhish17\\Desktop\\RE\\gvcl\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\Vidhish17\\AppData\\Local\\Temp\\ipykernel_4660\\930009657.py:3: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  cov_matrix = np.cov(data, rowvar=False)\n",
      "c:\\Users\\Vidhish17\\Desktop\\RE\\gvcl\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\Vidhish17\\Desktop\\RE\\gvcl\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.14535952, 0.19212993, 0.        , 0.        ,\n",
       "       0.25900441, 0.        , 0.        , 0.40350614])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi, mu, sigma = fit(x_train, y_train)\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.57725302e-03 4.46485014e-05 5.49697767e-09 3.74644902e-09\n",
      " 6.54979821e-10 1.08925849e-11 7.16087011e-12 2.68263755e-14]\n",
      "4.50803229488527e-69\n",
      "[1.59978556e-03 2.63266674e-05 2.99291496e-09 2.14256002e-09\n",
      " 2.65445188e-10 8.67472790e-12 4.68453711e-12 2.43879705e-14]\n",
      "7.104902175749669e-71\n",
      "[1.40057513e-03 1.97680463e-05 3.00999151e-09 1.51169445e-09\n",
      " 2.35017491e-10 8.90622886e-12 3.83441100e-12 2.57598144e-14]\n",
      "2.604563067639865e-71\n",
      "[1.61647108e-03 2.52874586e-05 2.70077971e-09 1.80270244e-09\n",
      " 3.80596594e-10 8.56490638e-12 4.30931266e-12 1.71915105e-14]\n",
      "4.806134130669556e-71\n"
     ]
    }
   ],
   "source": [
    "for label in [int(i) for i in data['class'].unique()]:\n",
    "    print(np.linalg.eigvals(sigma[label]))\n",
    "    print(np.linalg.det(sigma[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_gaussian_pdf(x, mean, cov):\n",
    "    d = mean.shape[0]\n",
    "    exponent = -0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(cov)), (x - mean))\n",
    "    prefactor = 1 / np.sqrt((2 * np.pi) ** d * np.linalg.det(cov))\n",
    "    #print(\"{} * {} = {}\".format(prefactor, np.exp(exponent), prefactor* np.exp(exponent)))\n",
    "    return np.exp(exponent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking If The Obtained Matrices are Positive Semidefinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.57725302e-03 4.46485014e-05 5.49697767e-09 3.74644902e-09\n",
      " 6.54979821e-10 1.08925849e-11 7.16087011e-12 2.68263755e-14]\n",
      "Class 2: The matrix is positive semidefinite.\n",
      "\n",
      "\n",
      "[1.59978556e-03 2.63266674e-05 2.99291496e-09 2.14256002e-09\n",
      " 2.65445188e-10 8.67472790e-12 4.68453711e-12 2.43879705e-14]\n",
      "Class 8: The matrix is positive semidefinite.\n",
      "\n",
      "\n",
      "[1.40057513e-03 1.97680463e-05 3.00999151e-09 1.51169445e-09\n",
      " 2.35017491e-10 8.90622886e-12 3.83441100e-12 2.57598144e-14]\n",
      "Class 1: The matrix is positive semidefinite.\n",
      "\n",
      "\n",
      "[1.61647108e-03 2.52874586e-05 2.70077971e-09 1.80270244e-09\n",
      " 3.80596594e-10 8.56490638e-12 4.30931266e-12 1.71915105e-14]\n",
      "Class 5: The matrix is positive semidefinite.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def is_positive_semidefinite(matrix):\n",
    "    eigenvalues, _ = np.linalg.eig(matrix)\n",
    "    print(eigenvalues)\n",
    "    return np.all(eigenvalues >= 0)\n",
    "\n",
    "for i in [int(i) for i in data['class'].unique()]:\n",
    "    matrix = sigma[i]  # Example matrix\n",
    "    positive_semidefinite = is_positive_semidefinite(matrix)\n",
    "    if positive_semidefinite:\n",
    "        print(f\"Class {i}: The matrix is positive semidefinite.\")\n",
    "    else:\n",
    "        print(f\"Class {i}: The matrix is NOT positive semidefinite.\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53335, 8)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Feature Densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vidhish17\\AppData\\Local\\Temp\\ipykernel_4660\\2168344499.py:18: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  probs = [x/deno for x in rel_probs]\n"
     ]
    }
   ],
   "source": [
    "# feature_densities = []\n",
    "# for i in range (x_test.shape[0]):\n",
    "#     feature_density = 0\n",
    "#     for label in [int(i) for i in data['class'].unique()]:\n",
    "#         feature_density += phi[label]*multivariate_gaussian_pdf(x_test[i], mu[label], sigma[label])\n",
    "#     feature_densities.append([x_test[i], feature_density])\n",
    "\n",
    "feature_densities = []\n",
    "labels = [int(i) for i in data['class'].unique()]\n",
    "\n",
    "for i in range (x_test.shape[0]):\n",
    "    rel_probs = []\n",
    "    deno = 0\n",
    "    for label in labels:\n",
    "        x = multivariate_gaussian_pdf(x_test[i], mu[label], sigma[label])\n",
    "        deno += x\n",
    "        rel_probs.append(x)\n",
    "    probs = [x/deno for x in rel_probs]\n",
    "    feature_density = 0\n",
    "    for j in range (len(labels)):\n",
    "        feature_density += phi[labels[j]]*probs[j]\n",
    "    feature_densities.append([x_test[i], feature_density])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.1311e-01, 1.3480e-02, 3.2556e-01, 9.8820e-01, 4.0640e-01,\n",
       "        1.1800e-02, 5.8181e-01, 1.9000e-04]),\n",
       " 0.19212995088078952]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(feature_densities))\n",
    "feature_densities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2948 - accuracy: 0.4229 - val_loss: 1.3760 - val_accuracy: 0.3327\n",
      "Epoch 2/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2859 - accuracy: 0.4240 - val_loss: 1.3715 - val_accuracy: 0.3250\n",
      "Epoch 3/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2819 - accuracy: 0.4252 - val_loss: 1.3663 - val_accuracy: 0.3351\n",
      "Epoch 4/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2802 - accuracy: 0.4259 - val_loss: 1.3762 - val_accuracy: 0.3321\n",
      "Epoch 5/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2793 - accuracy: 0.4261 - val_loss: 1.3879 - val_accuracy: 0.3343\n",
      "Epoch 6/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2788 - accuracy: 0.4261 - val_loss: 1.3704 - val_accuracy: 0.3420\n",
      "Epoch 7/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2785 - accuracy: 0.4262 - val_loss: 1.3662 - val_accuracy: 0.3385\n",
      "Epoch 8/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2778 - accuracy: 0.4268 - val_loss: 1.3747 - val_accuracy: 0.3379\n",
      "Epoch 9/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2778 - accuracy: 0.4264 - val_loss: 1.3733 - val_accuracy: 0.3426\n",
      "Epoch 10/10\n",
      "6667/6667 [==============================] - 8s 1ms/step - loss: 1.2775 - accuracy: 0.4262 - val_loss: 1.3722 - val_accuracy: 0.3348\n",
      "1667/1667 [==============================] - 1s 775us/step\n",
      "Per-point softmax entropy: [1.2032157 1.2820204 1.2820204 ... 1.2820204 1.2820204 1.2820204]\n"
     ]
    }
   ],
   "source": [
    "X = data[geometric_features].values\n",
    "y = data['class'].values  # Get class labels\n",
    "\n",
    "# Filter out classes not present in the dataset\n",
    "num_classes = len(data['class'].unique())  # Update to the number of present classes (1, 2, 5, 8)\n",
    "classes_present = [int(i) for i in data['class'].unique()]  # Classes present in the dataset\n",
    "class_mapping = {cls: i for i, cls in enumerate(classes_present)}\n",
    "y_mapped = np.array([class_mapping[cls] for cls in y])\n",
    "\n",
    "# Convert class labels to one-hot encoding\n",
    "y_onehot = tf.one_hot(y_mapped, depth=num_classes)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(len(geometric_features),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(4, activation='softmax')  # Output layer with softmax activation for the present classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y_onehot, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "softmax_probs = model.predict(x_test)\n",
    "entropy = -np.sum(softmax_probs * np.log(softmax_probs), axis=-1)\n",
    "\n",
    "print(\"Per-point softmax entropy:\", entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data)\n",
    "# print(softmax_probs)\n",
    "# print(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39794594, 0.3580835 , 0.05065088, 0.19331975],\n",
       "       [0.14135127, 0.419494  , 0.14658503, 0.29256967],\n",
       "       [0.14135127, 0.419494  , 0.14658503, 0.29256967],\n",
       "       ...,\n",
       "       [0.14135127, 0.419494  , 0.14658503, 0.29256967],\n",
       "       [0.14135127, 0.419494  , 0.14658503, 0.29256967],\n",
       "       [0.14135127, 0.419494  , 0.14658503, 0.29256967]], dtype=float32)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = np.sum(softmax_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000001, 1.       , 1.       , ..., 1.       , 1.       ,\n",
       "       1.       ], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "unique_values = np.unique(row_sums)\n",
    "\n",
    "# Printing values rounded till 6 decimal places\n",
    "print([round(i, 6) for i in unique_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(266675, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing for entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[geometric_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8334/8334 [==============================] - 8s 966us/step - loss: 1.3077 - accuracy: 0.4051\n",
      "Epoch 2/10\n",
      "8334/8334 [==============================] - 8s 949us/step - loss: 1.2985 - accuracy: 0.4091\n",
      "Epoch 3/10\n",
      "8334/8334 [==============================] - 8s 977us/step - loss: 1.2965 - accuracy: 0.4103\n",
      "Epoch 4/10\n",
      "8334/8334 [==============================] - 8s 967us/step - loss: 1.2957 - accuracy: 0.4103\n",
      "Epoch 5/10\n",
      "8334/8334 [==============================] - 8s 935us/step - loss: 1.2953 - accuracy: 0.4103\n",
      "Epoch 6/10\n",
      "8334/8334 [==============================] - 8s 939us/step - loss: 1.2948 - accuracy: 0.4104\n",
      "Epoch 7/10\n",
      "8334/8334 [==============================] - 8s 974us/step - loss: 1.2943 - accuracy: 0.4104\n",
      "Epoch 8/10\n",
      "8334/8334 [==============================] - 8s 953us/step - loss: 1.2941 - accuracy: 0.4103\n",
      "Epoch 9/10\n",
      "8334/8334 [==============================] - 8s 951us/step - loss: 1.2937 - accuracy: 0.4104\n",
      "Epoch 10/10\n",
      "8334/8334 [==============================] - 8s 950us/step - loss: 1.2936 - accuracy: 0.4105\n",
      "8334/8334 [==============================] - 7s 823us/step\n",
      "Per-point softmax entropy: [1.269068  1.2678665 1.2662933 ... 1.2596345 1.2615609 1.2599593]\n"
     ]
    }
   ],
   "source": [
    "X = data[geometric_features].values\n",
    "y = data['class'].values  # Get class labels\n",
    "\n",
    "# Filter out classes not present in the dataset\n",
    "num_classes = len(data['class'].unique())  # Update to the number of present classes (1, 2, 5, 8)\n",
    "classes_present = [int(i) for i in data['class'].unique()]  # Classes present in the dataset\n",
    "class_mapping = {cls: i for i, cls in enumerate(classes_present)}\n",
    "y_mapped = np.array([class_mapping[cls] for cls in y])\n",
    "\n",
    "# Convert class labels to one-hot encoding\n",
    "y_onehot = tf.one_hot(y_mapped, depth=num_classes)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(len(geometric_features),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(4, activation='softmax')  # Output layer with softmax activation for the present classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y_onehot, epochs=10, batch_size=32)\n",
    "\n",
    "softmax_probs = model.predict(x)\n",
    "entropy = -np.sum(softmax_probs * np.log(softmax_probs), axis=-1)\n",
    "\n",
    "print(\"Per-point softmax entropy:\", entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vidhish17\\AppData\\Local\\Temp\\ipykernel_4660\\83269348.py:11: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  probs = [x1/deno for x1 in rel_probs]\n"
     ]
    }
   ],
   "source": [
    "feature_densities = []\n",
    "labels = [int(i) for i in data['class'].unique()]\n",
    "\n",
    "for i in range (x.shape[0]):\n",
    "    rel_probs = []\n",
    "    deno = 0\n",
    "    for label in labels:\n",
    "        x1 = multivariate_gaussian_pdf(x[i], mu[label], sigma[label])\n",
    "        deno += x1\n",
    "        rel_probs.append(x1)\n",
    "    probs = [x1/deno for x1 in rel_probs]\n",
    "    feature_density = 0\n",
    "    for j in range (len(labels)):\n",
    "        feature_density += phi[labels[j]]*probs[j]\n",
    "    feature_densities.append([x[i], feature_density])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 1, 5]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['feature_density'] = [x[1] for x in feature_densities]\n",
    "data['softmax_probs'] = [x for x in softmax_probs]\n",
    "data['entropy'] = entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "      <th>eigenvalues_sum</th>\n",
       "      <th>omnivariance</th>\n",
       "      <th>eigentropy</th>\n",
       "      <th>anisotropy</th>\n",
       "      <th>planarity</th>\n",
       "      <th>linearity</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>verticality</th>\n",
       "      <th>feature_density</th>\n",
       "      <th>softmax_probs</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>1.10728</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10524</td>\n",
       "      <td>0.01319</td>\n",
       "      <td>0.31369</td>\n",
       "      <td>0.98523</td>\n",
       "      <td>0.79733</td>\n",
       "      <td>0.18790</td>\n",
       "      <td>0.01477</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.192130</td>\n",
       "      <td>[0.39686155, 0.28776363, 0.08122798, 0.23414679]</td>\n",
       "      <td>1.269068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>1.10974</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10538</td>\n",
       "      <td>0.01320</td>\n",
       "      <td>0.31396</td>\n",
       "      <td>0.98526</td>\n",
       "      <td>0.79686</td>\n",
       "      <td>0.18839</td>\n",
       "      <td>0.01474</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.192130</td>\n",
       "      <td>[0.39831564, 0.28716394, 0.08070589, 0.23381454]</td>\n",
       "      <td>1.267866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001541</td>\n",
       "      <td>1.11221</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10552</td>\n",
       "      <td>0.01321</td>\n",
       "      <td>0.31424</td>\n",
       "      <td>0.98528</td>\n",
       "      <td>0.79624</td>\n",
       "      <td>0.18904</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.192130</td>\n",
       "      <td>[0.40018854, 0.2864071, 0.080026716, 0.23337767]</td>\n",
       "      <td>1.266293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001541</td>\n",
       "      <td>1.11221</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10552</td>\n",
       "      <td>0.01321</td>\n",
       "      <td>0.31424</td>\n",
       "      <td>0.98528</td>\n",
       "      <td>0.79624</td>\n",
       "      <td>0.18904</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.192130</td>\n",
       "      <td>[0.40018854, 0.2864071, 0.080026716, 0.23337767]</td>\n",
       "      <td>1.266293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003545</td>\n",
       "      <td>1.11714</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10593</td>\n",
       "      <td>0.01324</td>\n",
       "      <td>0.31502</td>\n",
       "      <td>0.98535</td>\n",
       "      <td>0.79561</td>\n",
       "      <td>0.18974</td>\n",
       "      <td>0.01465</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.192130</td>\n",
       "      <td>[0.40247092, 0.28537217, 0.07926737, 0.2328895]</td>\n",
       "      <td>1.264449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266670</th>\n",
       "      <td>1.066120</td>\n",
       "      <td>1.76079</td>\n",
       "      <td>0.021406</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10721</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.98564</td>\n",
       "      <td>0.78459</td>\n",
       "      <td>0.20106</td>\n",
       "      <td>0.01436</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.192129</td>\n",
       "      <td>[0.40094736, 0.3067748, 0.07802903, 0.21424882]</td>\n",
       "      <td>1.258036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266671</th>\n",
       "      <td>1.066280</td>\n",
       "      <td>1.76079</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.10719</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.31737</td>\n",
       "      <td>0.98565</td>\n",
       "      <td>0.78448</td>\n",
       "      <td>0.20117</td>\n",
       "      <td>0.01435</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.192129</td>\n",
       "      <td>[0.40090486, 0.3070119, 0.07801785, 0.21406539]</td>\n",
       "      <td>1.257966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266672</th>\n",
       "      <td>1.066430</td>\n",
       "      <td>1.76326</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.10699</td>\n",
       "      <td>0.01331</td>\n",
       "      <td>0.31700</td>\n",
       "      <td>0.98561</td>\n",
       "      <td>0.78687</td>\n",
       "      <td>0.19874</td>\n",
       "      <td>0.01439</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.192131</td>\n",
       "      <td>[0.4013549, 0.30219346, 0.078306094, 0.2181455]</td>\n",
       "      <td>1.259634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266673</th>\n",
       "      <td>1.066430</td>\n",
       "      <td>1.76572</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.10677</td>\n",
       "      <td>0.01329</td>\n",
       "      <td>0.31659</td>\n",
       "      <td>0.98556</td>\n",
       "      <td>0.78986</td>\n",
       "      <td>0.19569</td>\n",
       "      <td>0.01444</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.192131</td>\n",
       "      <td>[0.4018129, 0.2961559, 0.07865931, 0.22337182]</td>\n",
       "      <td>1.261561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266674</th>\n",
       "      <td>1.069670</td>\n",
       "      <td>1.76326</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.10676</td>\n",
       "      <td>0.01329</td>\n",
       "      <td>0.31656</td>\n",
       "      <td>0.98558</td>\n",
       "      <td>0.78720</td>\n",
       "      <td>0.19838</td>\n",
       "      <td>0.01442</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.192131</td>\n",
       "      <td>[0.40121934, 0.30164543, 0.07836954, 0.2187657]</td>\n",
       "      <td>1.259959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266675 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x        y         z  class  eigenvalues_sum  omnivariance  \\\n",
       "0       0.001387  1.10728  0.017115    2.0          0.10524       0.01319   \n",
       "1       0.001387  1.10974  0.017115    2.0          0.10538       0.01320   \n",
       "2       0.001541  1.11221  0.017115    2.0          0.10552       0.01321   \n",
       "3       0.001541  1.11221  0.017115    2.0          0.10552       0.01321   \n",
       "4       0.003545  1.11714  0.017115    2.0          0.10593       0.01324   \n",
       "...          ...      ...       ...    ...              ...           ...   \n",
       "266670  1.066120  1.76079  0.021406    5.0          0.10721       0.01333   \n",
       "266671  1.066280  1.76079  0.017115    8.0          0.10719       0.01333   \n",
       "266672  1.066430  1.76326  0.017115    8.0          0.10699       0.01331   \n",
       "266673  1.066430  1.76572  0.017115    8.0          0.10677       0.01329   \n",
       "266674  1.069670  1.76326  0.017115    8.0          0.10676       0.01329   \n",
       "\n",
       "        eigentropy  anisotropy  planarity  linearity  sphericity  verticality  \\\n",
       "0          0.31369     0.98523    0.79733    0.18790     0.01477      0.00002   \n",
       "1          0.31396     0.98526    0.79686    0.18839     0.01474      0.00002   \n",
       "2          0.31424     0.98528    0.79624    0.18904     0.01472      0.00002   \n",
       "3          0.31424     0.98528    0.79624    0.18904     0.01472      0.00002   \n",
       "4          0.31502     0.98535    0.79561    0.18974     0.01465      0.00002   \n",
       "...            ...         ...        ...        ...         ...          ...   \n",
       "266670     0.31740     0.98564    0.78459    0.20106     0.01436      0.00014   \n",
       "266671     0.31737     0.98565    0.78448    0.20117     0.01435      0.00014   \n",
       "266672     0.31700     0.98561    0.78687    0.19874     0.01439      0.00014   \n",
       "266673     0.31659     0.98556    0.78986    0.19569     0.01444      0.00015   \n",
       "266674     0.31656     0.98558    0.78720    0.19838     0.01442      0.00014   \n",
       "\n",
       "        feature_density                                     softmax_probs  \\\n",
       "0              0.192130  [0.39686155, 0.28776363, 0.08122798, 0.23414679]   \n",
       "1              0.192130  [0.39831564, 0.28716394, 0.08070589, 0.23381454]   \n",
       "2              0.192130  [0.40018854, 0.2864071, 0.080026716, 0.23337767]   \n",
       "3              0.192130  [0.40018854, 0.2864071, 0.080026716, 0.23337767]   \n",
       "4              0.192130   [0.40247092, 0.28537217, 0.07926737, 0.2328895]   \n",
       "...                 ...                                               ...   \n",
       "266670         0.192129   [0.40094736, 0.3067748, 0.07802903, 0.21424882]   \n",
       "266671         0.192129   [0.40090486, 0.3070119, 0.07801785, 0.21406539]   \n",
       "266672         0.192131   [0.4013549, 0.30219346, 0.078306094, 0.2181455]   \n",
       "266673         0.192131    [0.4018129, 0.2961559, 0.07865931, 0.22337182]   \n",
       "266674         0.192131   [0.40121934, 0.30164543, 0.07836954, 0.2187657]   \n",
       "\n",
       "         entropy  \n",
       "0       1.269068  \n",
       "1       1.267866  \n",
       "2       1.266293  \n",
       "3       1.266293  \n",
       "4       1.264449  \n",
       "...          ...  \n",
       "266670  1.258036  \n",
       "266671  1.257966  \n",
       "266672  1.259634  \n",
       "266673  1.261561  \n",
       "266674  1.259959  \n",
       "\n",
       "[266675 rows x 15 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    266548.000000\n",
       "mean          0.240034\n",
       "std           0.020484\n",
       "min           0.192109\n",
       "25%           0.236779\n",
       "50%           0.251728\n",
       "75%           0.251728\n",
       "max           0.259380\n",
       "Name: feature_density, dtype: float64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_density'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    266675.000000\n",
       "mean          1.289849\n",
       "std           0.025749\n",
       "min           1.151420\n",
       "25%           1.298445\n",
       "50%           1.299515\n",
       "75%           1.299515\n",
       "max           1.362504\n",
       "Name: entropy, dtype: float64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(f\"CloudCompare/r{scale}-computed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gvcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
